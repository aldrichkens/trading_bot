{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0038cf8-4a0f-41d5-970b-3dae9b9a9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone, date\n",
    "from scipy.signal import find_peaks\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2995cc47-42f5-4108-bed9-db4ae1715e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"parameters.txt\", \"r\") as file:\n",
    "    exec(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a03e725-05f7-4509-8d5d-0cab12474c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions of the buy diagram ratio module\n",
    "\n",
    "def convert_maxima_to_LL_LH_df(Pay, p1_range_localmaximas):\n",
    "    Pa = p1_range_localmaximas[p1_range_localmaximas['high'] == Pay].drop(['open','low','close'], axis=1)\n",
    "    Pa = Pa.drop_duplicates(subset=['high'], keep='last')\n",
    "    Pa = Pa.rename(columns={\"high\":\"price\"})\n",
    "    return Pa\n",
    "    \n",
    "def convert_minima_to_LL_LH_df(Pay, condition, p1_range_localminimas):\n",
    "    Pa = p1_range_localminimas[(p1_range_localminimas['low'] == Pay) & condition].drop(['open','high','close'], axis=1)  \n",
    "    Pa = Pa.drop_duplicates(subset=['low'], keep='last')\n",
    "    Pa = Pa.rename(columns={\"low\":\"price\"})\n",
    "    return Pa\n",
    "\n",
    "def compute_index_Pa_x(Pay, p1_range_localmaximas):\n",
    "    try:\n",
    "        Pay_index = p1_range_localmaximas[p1_range_localmaximas['high'] == Pay].index[-1]\n",
    "    except IndexError as IE:\n",
    "        Pay_index = None\n",
    "    return Pay_index\n",
    "\n",
    "\n",
    "def create_tuples_p1_p3(df):\n",
    "    p1_p2_p3 = []\n",
    "    max_index = df.index.max()\n",
    "    no_of_comb = ((max_index + 1) // 2) -1  # +1 to include the last element for odd lengths\n",
    "    for i in range(no_of_comb):\n",
    "        p1_p2_p3.append((max_index, max_index - 2*(i+1) + 1, max_index - 2*(i+1)))\n",
    "    return p1_p2_p3\n",
    "\n",
    "def create_empty_p1_and_p2_and_p3_df():\n",
    "    p1 = pd.DataFrame(columns=['time','price'])\n",
    "    p1 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    p2 = pd.DataFrame(columns=['time','price'])\n",
    "    p2 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    p3 = pd.DataFrame(columns=['time','price'])\n",
    "    p3 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    return p1, p2, p3\n",
    "\n",
    "def create_empty_time_price_df():\n",
    "    df = pd.DataFrame(columns=['time','price'])\n",
    "    df = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    return df\n",
    "\n",
    "def create_empty_time_open_high_low_close_df():\n",
    "    df = pd.DataFrame(columns=['time','open','high','low','close'])\n",
    "    df = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'open': pd.Series(dtype='float'),\n",
    "                      'high': pd.Series(dtype='float'), 'low': pd.Series(dtype='float'),\n",
    "                      'close': pd.Series(dtype='float')})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91616590-77b4-4d69-bbf5-783be88f78bb",
   "metadata": {},
   "source": [
    "### START OF FAKE VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8543cca3-825c-408f-aaca-a78b959f5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fake Values only in here since this is backtest\n",
    "buy_tp = 1000\n",
    "#Importing the CSV file\n",
    "path = f\"./OHLC_data/GBPUSD_20250129_20250131.csv\"\n",
    "OHLC_df = pd.read_csv(path)\n",
    "OHLC_df['time'] = pd.to_datetime(OHLC_df['time'], format='%Y-%m-%d %H:%M:%S')\n",
    "# DATA TO BE TESTED\n",
    "mask = (OHLC_df[\"time\"] >= \"2025-01-29 10:00:00\") & (OHLC_df[\"time\"] <= \"2025-01-29 16:00:00\")\n",
    "rates_frame = OHLC_df[mask]\n",
    "Last_110 = OHLC_df[mask].tail(110)\n",
    "MaxHighPrice = Last_110[\"high\"].max()\n",
    "MinLowPrice = Last_110[\"low\"].min()\n",
    "MaxHighPoint = Last_110[Last_110[\"high\"] == MaxHighPrice].iloc[[0]]\n",
    "MinLowPoint = Last_110[Last_110[\"low\"] == MinLowPrice].iloc[[0]]\n",
    "MaxHighTime = MaxHighPoint['time'].iloc[0]\n",
    "MinLowTime = MinLowPoint['time'].iloc[0]\n",
    "rates_frame_p3 = rates_frame[rates_frame[\"time\"]<= MinLowTime].tail(110)\n",
    "p3_rates_frame = rates_frame[rates_frame[\"time\"]>= MinLowTime]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be39226-e7a3-4758-b7d1-ed2186e78124",
   "metadata": {},
   "source": [
    "### END OF FAKE VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a09e1369-93ea-4568-a4ca-50f1ea7ef988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO DETECT P1 P2 P3 for the EXTERNAL AND INTERNAL\n",
    "def obtain_p1_p2_p3(rates_frame_p3):\n",
    "    #obtaining the maximum point from the last 110 minutes for sells\n",
    "    Max_110_y = rates_frame_p3[\"high\"].max()\n",
    "    Max_110 = rates_frame_p3[rates_frame_p3[\"high\"] == Max_110_y].iloc[[-1]]\n",
    "    \n",
    "    #obtaining the minimum point from the last 110 minutes for sells\n",
    "    Min_110_y = rates_frame_p3[\"low\"].min()\n",
    "    Min_110 = rates_frame_p3[rates_frame_p3[\"low\"] == Min_110_y].iloc[[-1]]\n",
    "    \n",
    "    # Creating a new dataframe for the start and end of the minimum points in order to grab the data of local maxima and minima in an uptrend\n",
    "    p1_range_start_time = Max_110['time'].iloc[-1]\n",
    "    p1_range_end_time = Min_110[\"time\"].iloc[-1]\n",
    "    mask = rates_frame_p3[\"time\"].ge(p1_range_start_time) & rates_frame_p3[\"time\"].le(p1_range_end_time)\n",
    "    p1_range = rates_frame_p3[mask].reset_index(drop=True)\n",
    "    \n",
    "    # Find the index of local maximas\n",
    "    local_maximas_i,_ = find_peaks(p1_range['high'].values)\n",
    "    local_maximas_i = np.array(local_maximas_i)\n",
    "    \n",
    "    # Find the index of the local minima by inverting the data\n",
    "    local_minimas_i,_ = find_peaks(-p1_range['low'].values)\n",
    "    local_minimas_i = np.array(local_minimas_i)\n",
    "    \n",
    "    #Obtaining the dataframe of the local minimas and local maximas\n",
    "    p1_range_localminimas = p1_range[p1_range.index.isin(local_minimas_i)].reset_index(drop=True)\n",
    "    p1_range_localmaximas = p1_range[p1_range.index.isin(local_maximas_i)].reset_index(drop=True)\n",
    "    \n",
    "    # Finding the value of Pay1\n",
    "    Pay1 = Max_110_y\n",
    "    \n",
    "    #to find the y value of the possible 2nd local minima:\n",
    "    Pay3 = p1_range_localmaximas[\"high\"].max()\n",
    "    \n",
    "    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "    Pay3_index_range = Pay3_index\n",
    "    \n",
    "    while True:\n",
    "        #finding the index of the 1st local minima in the series \"p1_range_localminimas\" as P2\n",
    "        condition1 = p1_range_localminimas[\"time\"].ge(p1_range.iloc[0,0])\n",
    "        condition2 = p1_range_localminimas[\"time\"].le(p1_range_localmaximas.iloc[Pay3_index,0])\n",
    "        condition = condition1 & condition2\n",
    "        \n",
    "        Pay2 = p1_range_localminimas[condition == True]['low'].values\n",
    "    \n",
    "        try:\n",
    "            #finding the index of the 1st local minima in the series \"p1_range_localminimas\" as P2\n",
    "            condition1 = p1_range_localminimas[\"time\"].ge(p1_range.iloc[0,0])\n",
    "            condition2 = p1_range_localminimas[\"time\"].le(p1_range_localmaximas.iloc[Pay3_index,0])\n",
    "            condition = condition1 & condition2\n",
    "        \n",
    "            #to find the y value of the 1st local maxima:\n",
    "            Pay2 = p1_range_localminimas[condition == True]['low'].values\n",
    "            if len(Pay2) == 0:\n",
    "                #proceed with the next pay3 index and rerun the while loop\n",
    "                Pay3_index_range = Pay3_index_range + 1\n",
    "                Pay3 = p1_range_localmaximas.iloc[Pay3_index_range:,2].max()\n",
    "                Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "                continue\n",
    "            else:\n",
    "                #if value exists, find the minimum\n",
    "                Pay2 = min(Pay2)\n",
    "                break\n",
    "        except IndexError as err1:\n",
    "            break\n",
    "        except ValueError as ve:\n",
    "            continue\n",
    "        except TypeError as te:\n",
    "            break\n",
    "    \n",
    "            \n",
    "    #Making a new dataframe of the higher highs and higher lows approaching P3 in chronological order\n",
    "    LL_LH = create_empty_time_price_df()\n",
    "    \n",
    "    #Grabbing the data attached to Pay*\n",
    "    mask = rates_frame_p3['high'] == Pay1\n",
    "    pa1 = rates_frame_p3[mask].drop(['open','low','close'], axis=1).drop_duplicates(subset=['high'], keep='last').rename(columns={\"high\":\"price\"})\n",
    "    LL_LH_df = pd.concat([LL_LH, pa1], ignore_index=True)\n",
    "    \n",
    "    Pa2 = p1_range_localminimas[p1_range_localminimas['low'] == Pay2].drop(['open','high','close'], axis=1)\n",
    "    Pa2 = Pa2.drop_duplicates(subset=['low'], keep='last')\n",
    "    Pa2 = Pa2.rename(columns={\"low\":\"price\"})\n",
    "    LL_LH_df = pd.concat([LL_LH_df, Pa2], ignore_index=True)\n",
    "    LL_LH_df = pd.concat([LL_LH_df, convert_maxima_to_LL_LH_df(Pay3, p1_range_localmaximas)], ignore_index=True)\n",
    "    \n",
    "    #Resetting the values to avoid issues\n",
    "    Pay2 = Pay1_index = Pay3_index = 0\n",
    "    \n",
    "    #Assigning new values to find new sets of Pa2, Pa3\n",
    "    Pay1 = Pay3\n",
    "    Pay1_index = compute_index_Pa_x(Pay1, p1_range_localmaximas)\n",
    "    \n",
    "    #Resetting the values to avoid issues\n",
    "    Pay3 = Pay3_index = 0\n",
    "    \n",
    "    #Finding the initial value of Pay3\n",
    "    try:\n",
    "        Pay3 = p1_range_localmaximas.iloc[Pay1_index+1:,2].max()\n",
    "        Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "    except IndexError as err1:\n",
    "        print('There is no next p3. Continue with the external P1-P2-P3...')\n",
    "        Pay3 = None\n",
    "    \n",
    "    if Pay3 != None:\n",
    "        #Finding the values of the lower lows and lower highs and appending it to the LL_HH_df\n",
    "        while True:\n",
    "            Pay3_index_range = 0\n",
    "            try:\n",
    "                # Check if the current Pay3_index is beyond the end of p1_range_localminimas\n",
    "                if Pay3_index > len(p1_range_localmaximas):\n",
    "                    print(f\"End of p1_range_localmaximas reached.{Pay3_index}\")\n",
    "                    break\n",
    "                    \n",
    "                #finding the index of the next local maxima\n",
    "                condition1 = p1_range_localminimas[\"time\"].ge(p1_range_localmaximas.iloc[Pay1_index,0])\n",
    "                condition2 = p1_range_localminimas[\"time\"].le(p1_range_localmaximas.iloc[Pay3_index,0])\n",
    "                condition = condition1 & condition2\n",
    "        \n",
    "                \n",
    "                #to find the y value of the next local minima:\n",
    "                Pay2 = p1_range_localminimas[condition == True]['low'].values\n",
    "                \n",
    "                #previous ll index\n",
    "                pLL_index = LL_LH_df[LL_LH_df['price'] == Pay1].index[0] - 1\n",
    "                pLLy = LL_LH_df.iloc[pLL_index,1]\n",
    "        \n",
    "                #if Pay2 isnt existing for the current Pay3\n",
    "                condition3 = len(Pay2) == 0\n",
    "                \n",
    "                #if the current Pay2 is more than the previous ll\n",
    "                try:\n",
    "                    condition4 = p1_range_localminimas[condition == True]['low'].values.min() > pLLy\n",
    "                except ValueError as err2:\n",
    "                    Pay3_index = Pay3_index+1\n",
    "                    Pay3 = p1_range_localmaximas.iloc[Pay3_index:,2].max()\n",
    "                    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "                    continue\n",
    "                    \n",
    "                if condition3 or condition4:\n",
    "                    #proceed with the next pay3 index and rerun the while loop\n",
    "                    Pay2 = 0\n",
    "                    Pay3_index_range = Pay3_index+1\n",
    "                    Pay3 = p1_range_localmaximas.iloc[Pay3_index_range:,2].max()\n",
    "                    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "                    continue\n",
    "                else:\n",
    "                    Pay2=Pay2.min()\n",
    "                    #Appending to the LL_LH_df \n",
    "                    condition5 = (p1_range_localminimas['low'] == Pay2) & condition\n",
    "                    LL_LH_df = pd.concat([LL_LH_df, convert_minima_to_LL_LH_df(Pay2, condition5, p1_range_localminimas)], ignore_index=True)\n",
    "                    LL_LH_df = pd.concat([LL_LH_df, convert_maxima_to_LL_LH_df(Pay3, p1_range_localmaximas)], ignore_index=True)\n",
    "                    \n",
    "                    #Assigning new values to find new sets of Pa2, Pa3\n",
    "                    Pay1 = Pay3\n",
    "                    Pay1_index = compute_index_Pa_x(Pay1, p1_range_localmaximas)\n",
    "                    \n",
    "                    #Finding the initial value of Pay3\n",
    "                    Pay3 = p1_range_localmaximas.iloc[Pay1_index+1:,2].max()\n",
    "                    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "                    continue\n",
    "            except IndexError as err1:\n",
    "                break\n",
    "            except TypeError as te:\n",
    "                break\n",
    "    \n",
    "        #Append Max_110 to the dataframe:\n",
    "        Min_110 = Min_110.drop(['open','high','close'], axis=1).rename(columns={\"low\":\"price\"})\n",
    "        LL_LH_df = pd.concat([LL_LH_df, Min_110], ignore_index=True)\n",
    "        \n",
    "        # Create a tuple combining the list of possible p1-p2-p3 (initial values)\n",
    "        p1_p2_p3i = create_tuples_p1_p3(LL_LH_df)\n",
    "        \n",
    "        # finding the right p1-p2-p3 in terms of ratios\n",
    "        p1_p2_p3_index = []\n",
    "        for i in p1_p2_p3i:\n",
    "            p3i=i[0]\n",
    "            p2i=i[1]\n",
    "            p1i=i[2]\n",
    "            p3y_p2y = LL_LH_df.iloc[p3i,1] - LL_LH_df.iloc[p2i,1]\n",
    "            p2y_p1y = LL_LH_df.iloc[p2i,1] - LL_LH_df.iloc[p1i,1]\n",
    "            p3x_p2x = LL_LH_df.iloc[p3i,0] - LL_LH_df.iloc[p2i,0]\n",
    "            p2x_p1x = LL_LH_df.iloc[p2i,0] - LL_LH_df.iloc[p1i,0]\n",
    "        \n",
    "            # conditions for finding the right p1-p2-p3\n",
    "            condition1 = 1.027 <= abs(p3y_p2y/p2y_p1y) <= 1.9286\n",
    "            try:\n",
    "                condition2 = 0.217 <= abs(p3x_p2x/p2x_p1x) <= 5\n",
    "            except ZeroDivisionError as err1:\n",
    "                condition2 = False\n",
    "                \n",
    "            condition3 = p2x_p1x > pd.Timedelta(minutes=1)\n",
    "            condition4 = pd.Timedelta(minutes=2) <= p2x_p1x <= pd.Timedelta(minutes=24)\n",
    "            condition5 = pd.Timedelta(minutes=2) <= p3x_p2x <= pd.Timedelta(minutes=28)\n",
    "            condition = condition1 & condition2 & condition3 & condition4 & condition5\n",
    "            \n",
    "            if condition:\n",
    "                p1_p2_p3_index.append(i)\n",
    "    \n",
    "            p1, p2, p3 = create_empty_p1_and_p2_and_p3_df()\n",
    "        \n",
    "        if len(p1_p2_p3_index) == 0:\n",
    "            return p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3\n",
    "            \n",
    "        else:\n",
    "            for p3i, p2i, p1i in p1_p2_p3_index:\n",
    "                new_p3 = LL_LH_df.iloc[[p3i]]\n",
    "                new_p2 = LL_LH_df.iloc[[p2i]]\n",
    "                new_p1 = LL_LH_df.iloc[[p1i]]\n",
    "                p3 = pd.concat([p3,new_p3], ignore_index=True)\n",
    "                p2 = pd.concat([p2,new_p2], ignore_index=True)\n",
    "                p1 = pd.concat([p1,new_p1], ignore_index=True)\n",
    "            return  p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3\n",
    "        \n",
    "        if len(p1) != len(p2):\n",
    "            print(\"Index error! P1 and P2 doesn't match!\")\n",
    "            return p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3\n",
    "            \n",
    "    elif Pay3 == None:\n",
    "        p1, p2, p3 = create_empty_p1_and_p2_and_p3_df()\n",
    "        return p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c200fcaa-3fea-4a08-9b8b-a23cae107c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_buy(rates_frame_p3, p3_rates_frame, buy_tp):\n",
    "    TP1_price = None\n",
    "    # OBTAINING THE EXTERNAL p1-p2-p3\n",
    "    (\n",
    "        p1_range_localminimas,\n",
    "        p1_range_localmaximas,\n",
    "        LL_LH_df,\n",
    "        p1,\n",
    "        p2,\n",
    "        p3\n",
    "    ) = obtain_p1_p2_p3(rates_frame_p3)\n",
    "\n",
    "    \n",
    "    # FINDING THE VALUES OF THE OHLC DATAFRAME FROM THE EXTERNAL P2 AND P3 to HAVE THE INTERNAL P1-P2-P3\n",
    "    if not len(p1) == 0 and not len(p2) == 0:\n",
    "        p1_internal_range_start_time = p2[\"time\"].iloc[-1]\n",
    "        p1_internal_range_end_time = p3[\"time\"].iloc[-1]\n",
    "        \n",
    "        mask = (p1_internal_range_start_time <= rates_frame_p3[\"time\"]) & (rates_frame_p3[\"time\"] <= p1_internal_range_end_time)\n",
    "        p1_internal_range = rates_frame_p3[mask]\n",
    "    \n",
    "    try: \n",
    "        (\n",
    "            p1_range_localminimas_internal,\n",
    "            p1_range_localmaximas_internal,\n",
    "            LL_LH_df_internal, p1_internal,\n",
    "            p2_internal,\n",
    "            p3_internal\n",
    "        ) = obtain_p1_p2_p3(p1_internal_range)\n",
    "    except (TypeError, ValueError) as TE_VE:\n",
    "        p1_internal, p2_internal, p3_internal = create_empty_p1_and_p2_and_p3_df()\n",
    "        p1_range_localminimas_internal = p1_range_localmaximas_internal = create_empty_time_open_high_low_close_df()\n",
    "        LL_LH_internal = create_empty_time_price_df()\n",
    "    except UnboundLocalError as ULE:\n",
    "        #if there is no p1-p2-p3 because of the time limits, it will return a ULE, therefore, find the p1-p2-p3 with another dataframe\n",
    "        #tail 42 is just temporary, gather more data for this\n",
    "        p1_internal_range = rates_frame_p3.tail(42)\n",
    "    \n",
    "        try:\n",
    "            (\n",
    "                p1_range_localminimas_internal,\n",
    "                p1_range_localmaximas_internal,\n",
    "                LL_LH_df_internal, p1_internal,\n",
    "                p2_internal,\n",
    "                p3_internal\n",
    "            ) = obtain_p1_p2_p3(p1_internal_range)\n",
    "        except (TypeError, UnboundLocalError) as TE_ULE:\n",
    "            p1_internal, p2_internal, p3_internal = create_empty_p1_and_p2_and_p3_df()\n",
    "            p1_range_localminimas_internal = p1_range_localmaximas_internal = create_empty_time_open_high_low_close_df()\n",
    "            LL_LH_df_internal = create_empty_time_price_df()\n",
    "\t\t\t\n",
    "    \n",
    "    # APPEND THE VALUES OF THE INTERNAL P1, P2, P3 to the external one. \n",
    "    p1 = pd.concat([p1,p1_internal], ignore_index=True)\n",
    "    p2 = pd.concat([p2,p2_internal], ignore_index=True)\n",
    "    p3 = pd.concat([p3,p3_internal], ignore_index=True)\n",
    "    \n",
    "    #SETTING THE INITIAL VALUE OF BUY TO \"NONE\"\n",
    "    Buy = None\n",
    "    \n",
    "    if (len(p1) == 0 and len(p2) == 0) and (len(p1) != len(p2)):\n",
    "        Buy = False\n",
    "        SL_price = None\n",
    "        OB_size = None\n",
    "        Entry_price = None\n",
    "        SL_size = None\n",
    "        p2_bos = p4 = create_empty_time_price_df()\n",
    "        return Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "        \n",
    "    try:\n",
    "\t\t#FINDING P4 RANGE DATAFRAME\n",
    "        p4_range = p3_rates_frame\n",
    "        \n",
    "        #FIND THE INITIAL VALUE OF P4 ( MINIMUM LOW IN THE P4 RANGE)\n",
    "        p4y = p4_range[\"high\"].max()\n",
    "        mask = p4_range[\"high\"] == p4y\n",
    "        p4 = p4_range[mask].drop(['open','low','close'], axis=1).rename(columns={\"high\":\"price\"}).iloc[[-1]]\n",
    "        \n",
    "        # FINDING EVERY POSSIBLE P2 AFTER BOS (IF THERE IS A BOS)\n",
    "        p4y = p4[\"price\"].iloc[0]\n",
    "        p2_index = 0\n",
    "        p2_bos = create_empty_time_price_df()\n",
    "\n",
    "    except IndexError as IE:\n",
    "        Buy = False\n",
    "        SL_price = None\n",
    "        OB_size = None\n",
    "        Entry_price = None\n",
    "        SL_size = None\n",
    "        p2_bos = p4 = create_empty_time_price_df()\n",
    "        return Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "\t\t\n",
    "    while p2_index < len(p2):\n",
    "        if p2[\"price\"].iloc[p2_index] < p4y:\n",
    "            #GRAB THE INDIVIDUAL P2 THAT CAUSED BOS\n",
    "            p2_bos = pd.concat([p2_bos,p2.iloc[[p2_index]]], ignore_index=True)\n",
    "            p2_index += 1\n",
    "        else:\n",
    "            p2_index += 1\n",
    "            continue  \n",
    "            \n",
    "    \n",
    "    # DECIDING WHETHER TO BUY OR NOT\n",
    "    if len(p2_bos) == 0:\n",
    "        Buy = False\n",
    "        SL_price = None\n",
    "        OB_size = None\n",
    "        Entry_price = None\n",
    "        SL_size = None\n",
    "        return Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "    else:\n",
    "        p2_bos = p2_bos.drop_duplicates(subset=[\"time\", \"price\"])\n",
    "        p1 = p1.drop_duplicates(subset=[\"time\", \"price\"])\n",
    "        p2 = p2.drop_duplicates(subset=[\"time\", \"price\"])\n",
    "        num_rows_p2 = p2.shape[0]\n",
    "        p3 = p3.drop_duplicates(subset=[\"time\", \"price\"])\n",
    "        p3 = p3.loc[p3.index.repeat(num_rows_p2)].reset_index(drop=True)\n",
    "        SL_price = round(p3[\"price\"].iloc[0] - breathing_room, pip_precision)\n",
    "        OB_size = round(p2_bos[\"price\"].max() - p3[\"price\"].iloc[0], pip_precision)\n",
    "        Entry_price = round(p2_bos[\"price\"].max() - 0.6*OB_size + breathing_room, pip_precision)\n",
    "        SL_size = round(Entry_price - SL_price, pip_precision)\n",
    "        TP1_price = round(Entry_price + (SL_size * RR_value), pip_precision)\n",
    "        TP_size = buy_tp - Entry_price\n",
    "        RR = TP_size / SL_size\n",
    "    \n",
    "        if RR >= RR_value:\n",
    "            Buy = True\n",
    "            return Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "        else:\n",
    "            Buy = False\n",
    "            return Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d949b2d8-77d7-4c47-8aa4-53e3a6bd4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify p4 before entry:\n",
    "def verify_p4(p2_bos,p3,p4,p3_rates_frame):\n",
    "    number_of_rows = p3.shape[0]\n",
    "    p4 = pd.concat([p4] * number_of_rows, ignore_index=True)\n",
    "    p4.reset_index(drop=True)\n",
    "    p4_is_valid = []\n",
    "    \n",
    "    for index, row in p2_bos.iterrows():\n",
    "        # OBTAINING THE PRICE AND TIME OF P2_BOS, P3 AND P4 and their difference\n",
    "        p4x = p4['time'].iloc[index]\n",
    "        p4y = p4['price'].iloc[index]\n",
    "        p3x = p3['time'].iloc[index]\n",
    "        p3y = p3['price'].iloc[index]\n",
    "        p2_bos_x = p2_bos['time'].iloc[index]\n",
    "        p2_bos_y = p2_bos['price'].iloc[index]\n",
    "        p4y_p3y = abs(p4y - p3y)\n",
    "        p3y_p2_bos_y = abs(p3y - p2_bos_y)\n",
    "        p3y_p4y = abs(p3y - p4y)\n",
    "        p2_bos_x_p3x = abs(p3x - p2_bos_x)\n",
    "        p3x_p4x = abs(p4x - p3x)\n",
    "            \n",
    "        # OBTAIN THE p4_rates_frame DATAFRAME:\n",
    "        mask = p3_rates_frame['time'] >= p4x\n",
    "        p4_rates_frame = p3_rates_frame[mask]\n",
    "        \n",
    "        #OBTAIN P5\n",
    "        p5y = p4_rates_frame[\"low\"].min()\n",
    "        mask = p4_rates_frame['low'] == p5y\n",
    "        p5 = p4_rates_frame[mask].iloc[0]\n",
    "        p5x = p5['time'] #time of p5\n",
    "        \n",
    "        # OBTAIN P3-P5 RATES FRAME\n",
    "        mask = (p3_rates_frame['time'] >= p3x) & (p3_rates_frame['time'] <= p5x)\n",
    "        p3_p5_rates_frame = p3_rates_frame[mask]\n",
    "        \n",
    "        # Obtain the lows in P3-P5 RATES FRAME that are below the P2_BOS_Y\n",
    "        mask = p3_p5_rates_frame['high'] > p2_bos_y\n",
    "        p3_p5_rates_frame_lows_below_p2_bos = p3_p5_rates_frame[mask]\n",
    "        \n",
    "        # calculate the time that price spent on the other side of the p2_bos:\n",
    "        bos_first_point_time = p3_p5_rates_frame_lows_below_p2_bos[\"time\"].iloc[0]\n",
    "        bos_last_point_time = p3_p5_rates_frame_lows_below_p2_bos[\"time\"].iloc[-1]\n",
    "        bos_time = bos_last_point_time - bos_first_point_time\n",
    "        \n",
    "        # OBTAINING THE RATIOS TO VALIDATE P4\n",
    "        condition1 = pd.Timedelta(minutes=1) <= (p4x - p3x) <= pd.Timedelta(minutes=33)\n",
    "        condition2 = 0.167 <= (p3x_p4x/p2_bos_x_p3x) <= 4.5\n",
    "        condition3 = 1.0219 <= (p4y_p3y/p3y_p2_bos_y) <= 1.8889\n",
    "        condition4 = pd.Timedelta(minutes=0) <= bos_time <= pd.Timedelta(minutes=17)\n",
    "        condition = condition1 & condition2 & condition3 & condition4\n",
    "        \n",
    "        if condition:\n",
    "            is_valid = True\n",
    "        elif condition == False:\n",
    "            is_valid = False\n",
    "        p4_is_valid.append(is_valid)\n",
    "    result = any(p4_is_valid)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8183dfb6-7907-4c03-b75d-09f063b9eff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4 = validate_and_buy(rates_frame_p3, p3_rates_frame, buy_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9a75638-80a0-4d0d-bc7d-3a79ec7a91c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-29 15:25:00</td>\n",
       "      <td>1.23943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    price\n",
       "0 2025-01-29 15:25:00  1.23943"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8017b462-1784-4961-8980-8b7dafbb790c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-29 15:31:00</td>\n",
       "      <td>1.24019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    price\n",
       "0 2025-01-29 15:31:00  1.24019"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4159faf-2928-4deb-a731-56ee432aa304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-29 15:36:00</td>\n",
       "      <td>1.2393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time   price\n",
       "0 2025-01-29 15:36:00  1.2393"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e7e6512e-8738-4ac1-a823-31ce8f1d6ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>2025-01-29 15:38:00</td>\n",
       "      <td>1.24047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time    price\n",
       "1417 2025-01-29 15:38:00  1.24047"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "910bdc7a-7c37-4cc2-aa36-616810c481db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4_is_valid = verify_p4(p2_bos,p3,p4,p3_rates_frame)\n",
    "p4_is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89095b80-1378-4c16-9183-66f8b530212f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dc44d4-0c1b-4a19-b08d-12537fa2f5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618ab38f-eafe-45cd-9558-d1d66228784b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b447d88f-8801-429c-bc04-7fafbafc838a",
   "metadata": {},
   "source": [
    "### delete cells after this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53b3a858-c5d4-462b-999c-f4dbd4aac62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP1_price = None\n",
    "# OBTAINING THE EXTERNAL p1-p2-p3\n",
    "(\n",
    "    p1_range_localminimas,\n",
    "    p1_range_localmaximas,\n",
    "    LL_LH_df,\n",
    "    p1,\n",
    "    p2,\n",
    "    p3\n",
    ") = obtain_p1_p2_p3(rates_frame_p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1554268c-e8c9-4529-85d6-f4db27419101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    time     open     high      low    close\n",
      "1306 2025-01-29 13:47:00  1.24195  1.24211  1.24189  1.24210\n",
      "1307 2025-01-29 13:48:00  1.24207  1.24212  1.24189  1.24191\n",
      "1308 2025-01-29 13:49:00  1.24191  1.24203  1.24178  1.24178\n",
      "1309 2025-01-29 13:50:00  1.24178  1.24178  1.24152  1.24152\n",
      "1310 2025-01-29 13:51:00  1.24149  1.24150  1.24129  1.24138\n",
      "...                  ...      ...      ...      ...      ...\n",
      "1411 2025-01-29 15:32:00  1.24009  1.24009  1.23956  1.23958\n",
      "1412 2025-01-29 15:33:00  1.23956  1.23972  1.23952  1.23961\n",
      "1413 2025-01-29 15:34:00  1.23963  1.23965  1.23951  1.23963\n",
      "1414 2025-01-29 15:35:00  1.23963  1.23963  1.23938  1.23942\n",
      "1415 2025-01-29 15:36:00  1.23939  1.23966  1.23930  1.23962\n",
      "\n",
      "[110 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(rates_frame_p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "254ef010-8935-451d-beeb-bb076bd6d4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time    price\n",
      "0 2025-01-29 15:00:00  1.24283\n",
      "1 2025-01-29 15:03:00  1.24206\n",
      "2 2025-01-29 15:05:00  1.24231\n",
      "3 2025-01-29 15:11:00  1.24113\n",
      "4 2025-01-29 15:12:00  1.24152\n",
      "5 2025-01-29 15:20:00  1.23988\n",
      "6 2025-01-29 15:21:00  1.24069\n",
      "7 2025-01-29 15:25:00  1.23943\n",
      "8 2025-01-29 15:31:00  1.24019\n",
      "9 2025-01-29 15:36:00  1.23930\n",
      "                 time    price\n",
      "0 2025-01-29 15:25:00  1.23943\n",
      "                 time    price\n",
      "0 2025-01-29 15:31:00  1.24019\n",
      "                 time   price\n",
      "0 2025-01-29 15:36:00  1.2393\n"
     ]
    }
   ],
   "source": [
    "print(LL_LH_df)\n",
    "print(p1)\n",
    "print(p2)\n",
    "print(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53640012-629b-456c-ad25-71f89654d0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  time     open     high      low    close\n",
      "0  2025-01-29 15:00:00  1.24252  1.24283  1.24246  1.24265\n",
      "1  2025-01-29 15:01:00  1.24267  1.24269  1.24231  1.24232\n",
      "2  2025-01-29 15:02:00  1.24231  1.24232  1.24207  1.24214\n",
      "3  2025-01-29 15:03:00  1.24215  1.24217  1.24206  1.24207\n",
      "4  2025-01-29 15:04:00  1.24206  1.24230  1.24206  1.24229\n",
      "5  2025-01-29 15:05:00  1.24228  1.24231  1.24215  1.24216\n",
      "6  2025-01-29 15:06:00  1.24216  1.24216  1.24192  1.24213\n",
      "7  2025-01-29 15:07:00  1.24213  1.24214  1.24180  1.24204\n",
      "8  2025-01-29 15:08:00  1.24204  1.24204  1.24180  1.24180\n",
      "9  2025-01-29 15:09:00  1.24176  1.24186  1.24161  1.24170\n",
      "10 2025-01-29 15:10:00  1.24175  1.24182  1.24140  1.24142\n",
      "11 2025-01-29 15:11:00  1.24140  1.24144  1.24113  1.24136\n",
      "12 2025-01-29 15:12:00  1.24136  1.24152  1.24125  1.24127\n",
      "13 2025-01-29 15:13:00  1.24129  1.24132  1.24117  1.24125\n",
      "14 2025-01-29 15:14:00  1.24125  1.24132  1.24106  1.24124\n",
      "15 2025-01-29 15:15:00  1.24120  1.24123  1.24069  1.24076\n",
      "16 2025-01-29 15:16:00  1.24076  1.24077  1.24051  1.24051\n",
      "17 2025-01-29 15:17:00  1.24050  1.24054  1.24020  1.24023\n",
      "18 2025-01-29 15:18:00  1.24021  1.24033  1.24004  1.24004\n",
      "19 2025-01-29 15:19:00  1.24004  1.24015  1.23998  1.24002\n",
      "20 2025-01-29 15:20:00  1.23988  1.24060  1.23988  1.24046\n",
      "21 2025-01-29 15:21:00  1.24045  1.24069  1.24045  1.24065\n",
      "22 2025-01-29 15:22:00  1.24064  1.24064  1.24029  1.24034\n",
      "23 2025-01-29 15:23:00  1.24034  1.24054  1.24005  1.24013\n",
      "24 2025-01-29 15:24:00  1.24013  1.24014  1.23976  1.23976\n",
      "25 2025-01-29 15:25:00  1.23962  1.23983  1.23943  1.23954\n",
      "26 2025-01-29 15:26:00  1.23962  1.23997  1.23953  1.23997\n",
      "27 2025-01-29 15:27:00  1.23996  1.24000  1.23965  1.23966\n",
      "28 2025-01-29 15:28:00  1.23971  1.23992  1.23959  1.23988\n",
      "29 2025-01-29 15:29:00  1.23989  1.24005  1.23983  1.23999\n",
      "30 2025-01-29 15:30:00  1.24000  1.24004  1.23963  1.23987\n",
      "31 2025-01-29 15:31:00  1.23993  1.24019  1.23982  1.24009\n",
      "32 2025-01-29 15:32:00  1.24009  1.24009  1.23956  1.23958\n",
      "33 2025-01-29 15:33:00  1.23956  1.23972  1.23952  1.23961\n",
      "34 2025-01-29 15:34:00  1.23963  1.23965  1.23951  1.23963\n",
      "35 2025-01-29 15:35:00  1.23963  1.23963  1.23938  1.23942\n",
      "36 2025-01-29 15:36:00  1.23939  1.23966  1.23930  1.23962\n"
     ]
    }
   ],
   "source": [
    "# FUNCTION TO DETECT P1 P2 P3 for the EXTERNAL AND INTERNAL\n",
    "#obtaining the maximum point from the last 110 minutes for sells\n",
    "Max_110_y = rates_frame_p3[\"high\"].max()\n",
    "Max_110 = rates_frame_p3[rates_frame_p3[\"high\"] == Max_110_y].iloc[[-1]]\n",
    "\n",
    "#obtaining the minimum point from the last 110 minutes for sells\n",
    "Min_110_y = rates_frame_p3[\"low\"].min()\n",
    "Min_110 = rates_frame_p3[rates_frame_p3[\"low\"] == Min_110_y].iloc[[-1]]\n",
    "\n",
    "# Creating a new dataframe for the start and end of the minimum points in order to grab the data of local maxima and minima in an uptrend\n",
    "p1_range_start_time = Max_110['time'].iloc[-1]\n",
    "p1_range_end_time = Min_110[\"time\"].iloc[-1]\n",
    "mask = rates_frame_p3[\"time\"].ge(p1_range_start_time) & rates_frame_p3[\"time\"].le(p1_range_end_time)\n",
    "p1_range = rates_frame_p3[mask].reset_index(drop=True)\n",
    "print(p1_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "285c6a1a-adfd-4169-a64d-e04e3081731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of local maximas\n",
    "local_maximas_i,_ = find_peaks(p1_range['high'].values)\n",
    "local_maximas_i = np.array(local_maximas_i)\n",
    "\n",
    "# Find the index of the local minima by inverting the data\n",
    "local_minimas_i,_ = find_peaks(-p1_range['low'].values)\n",
    "local_minimas_i = np.array(local_minimas_i)\n",
    "\n",
    "#Obtaining the dataframe of the local minimas and local maximas\n",
    "p1_range_localminimas = p1_range[p1_range.index.isin(local_minimas_i)].reset_index(drop=True)\n",
    "p1_range_localmaximas = p1_range[p1_range.index.isin(local_maximas_i)].reset_index(drop=True)\n",
    "\n",
    "# Finding the value of Pay1\n",
    "Pay1 = Max_110_y\n",
    "\n",
    "#to find the y value of the possible 2nd local minima:\n",
    "Pay3 = p1_range_localmaximas[\"high\"].max()\n",
    "\n",
    "Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "Pay3_index_range = Pay3_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26dba0f0-bce4-4f0f-9dd7-5abf76aff877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 time    price\n",
      "0 2025-01-29 15:00:00  1.24283\n",
      "1 2025-01-29 15:03:00  1.24206\n",
      "2 2025-01-29 15:05:00  1.24231\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    #finding the index of the 1st local minima in the series \"p1_range_localminimas\" as P2\n",
    "    condition1 = p1_range_localminimas[\"time\"].ge(p1_range.iloc[0,0])\n",
    "    condition2 = p1_range_localminimas[\"time\"].le(p1_range_localmaximas.iloc[Pay3_index,0])\n",
    "    condition = condition1 & condition2\n",
    "    \n",
    "    Pay2 = p1_range_localminimas[condition == True]['low'].values\n",
    "\n",
    "    try:\n",
    "        #finding the index of the 1st local minima in the series \"p1_range_localminimas\" as P2\n",
    "        condition1 = p1_range_localminimas[\"time\"].ge(p1_range.iloc[0,0])\n",
    "        condition2 = p1_range_localminimas[\"time\"].le(p1_range_localmaximas.iloc[Pay3_index,0])\n",
    "        condition = condition1 & condition2\n",
    "    \n",
    "        #to find the y value of the 1st local maxima:\n",
    "        Pay2 = p1_range_localminimas[condition == True]['low'].values\n",
    "        if len(Pay2) == 0:\n",
    "            #proceed with the next pay3 index and rerun the while loop\n",
    "            Pay3_index_range = Pay3_index_range + 1\n",
    "            Pay3 = p1_range_localmaximas.iloc[Pay3_index_range:,2].max()\n",
    "            Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "            continue\n",
    "        else:\n",
    "            #if value exists, find the minimum\n",
    "            Pay2 = min(Pay2)\n",
    "            break\n",
    "    except IndexError as err1:\n",
    "        break\n",
    "    except ValueError as ve:\n",
    "        continue\n",
    "    except TypeError as te:\n",
    "        break\n",
    "\n",
    "        \n",
    "#Making a new dataframe of the higher highs and higher lows approaching P3 in chronological order\n",
    "LL_LH = create_empty_time_price_df()\n",
    "\n",
    "#Grabbing the data attached to Pay*\n",
    "mask = rates_frame_p3['high'] == Pay1\n",
    "pa1 = rates_frame_p3[mask].drop(['open','low','close'], axis=1).drop_duplicates(subset=['high'], keep='last').rename(columns={\"high\":\"price\"})\n",
    "LL_LH_df = pd.concat([LL_LH, pa1], ignore_index=True)\n",
    "\n",
    "Pa2 = p1_range_localminimas[p1_range_localminimas['low'] == Pay2].drop(['open','high','close'], axis=1)\n",
    "Pa2 = Pa2.drop_duplicates(subset=['low'], keep='last')\n",
    "Pa2 = Pa2.rename(columns={\"low\":\"price\"})\n",
    "LL_LH_df = pd.concat([LL_LH_df, Pa2], ignore_index=True)\n",
    "LL_LH_df = pd.concat([LL_LH_df, convert_maxima_to_LL_LH_df(Pay3, p1_range_localmaximas)], ignore_index=True)\n",
    "print(LL_LH_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15bbd9d7-f745-48f4-8fac-a5ad9a12615e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24152\n"
     ]
    }
   ],
   "source": [
    "#Resetting the values to avoid issues\n",
    "Pay2 = Pay1_index = Pay3_index = 0\n",
    "\n",
    "#Assigning new values to find new sets of Pa2, Pa3\n",
    "Pay1 = Pay3\n",
    "Pay1_index = compute_index_Pa_x(Pay1, p1_range_localmaximas)\n",
    "\n",
    "#Resetting the values to avoid issues\n",
    "Pay3 = Pay3_index = 0\n",
    "\n",
    "#Finding the initial value of Pay3\n",
    "try:\n",
    "    Pay3 = p1_range_localmaximas.iloc[Pay1_index+1:,2].max()\n",
    "    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "except IndexError as err1:\n",
    "    print('There is no next p3. Continue with the external P1-P2-P3...')\n",
    "    Pay3 = None\n",
    "\n",
    "print(Pay3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4f238d8-3778-45f3-94b1-1f25566b174d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the values of the lower lows and lower highs and appending it to the LL_HH_df\n",
    "while True:\n",
    "    Pay3_index_range = 0\n",
    "    try:\n",
    "        # Check if the current Pay3_index is beyond the end of p1_range_localminimas\n",
    "        if Pay3_index > len(p1_range_localmaximas):\n",
    "            print(f\"End of p1_range_localmaximas reached.{Pay3_index}\")\n",
    "            # break\n",
    "            \n",
    "        #finding the index of the next local maxima\n",
    "        condition1 = p1_range_localminimas[\"time\"].ge(p1_range_localmaximas.iloc[Pay1_index,0])\n",
    "        condition2 = p1_range_localminimas[\"time\"].le(p1_range_localmaximas.iloc[Pay3_index,0])\n",
    "        condition = condition1 & condition2\n",
    "\n",
    "        \n",
    "        #to find the y value of the next local minima:\n",
    "        Pay2 = p1_range_localminimas[condition == True]['low'].values\n",
    "        \n",
    "        #previous ll index\n",
    "        pLL_index = LL_LH_df[LL_LH_df['price'] == Pay1].index[0] - 1\n",
    "        pLLy = LL_LH_df.iloc[pLL_index,1]\n",
    "\n",
    "        #if Pay2 isnt existing for the current Pay3\n",
    "        condition3 = len(Pay2) == 0\n",
    "        \n",
    "        #if the current Pay2 is more than the previous ll\n",
    "        try:\n",
    "            condition4 = p1_range_localminimas[condition == True]['low'].values.min() > pLLy\n",
    "        except ValueError as err2:\n",
    "            Pay3_index = Pay3_index+1\n",
    "            Pay3 = p1_range_localmaximas.iloc[Pay3_index:,2].max()\n",
    "            Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "            continue\n",
    "            \n",
    "        if condition3 or condition4:\n",
    "            #proceed with the next pay3 index and rerun the while loop\n",
    "            Pay2 = 0\n",
    "            Pay3_index_range = Pay3_index+1\n",
    "            Pay3 = p1_range_localmaximas.iloc[Pay3_index_range:,2].max()\n",
    "            Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "            continue\n",
    "        else:\n",
    "            Pay2=Pay2.min()\n",
    "            #Appending to the LL_LH_df \n",
    "            condition5 = (p1_range_localminimas['low'] == Pay2) & condition\n",
    "            LL_LH_df = pd.concat([LL_LH_df, convert_minima_to_LL_LH_df(Pay2, condition5, p1_range_localminimas)], ignore_index=True)\n",
    "            LL_LH_df = pd.concat([LL_LH_df, convert_maxima_to_LL_LH_df(Pay3, p1_range_localmaximas)], ignore_index=True)\n",
    "            \n",
    "            #Assigning new values to find new sets of Pa2, Pa3\n",
    "            Pay1 = Pay3\n",
    "            Pay1_index = compute_index_Pa_x(Pay1, p1_range_localmaximas)\n",
    "            \n",
    "            #Finding the initial value of Pay3\n",
    "            Pay3 = p1_range_localmaximas.iloc[Pay1_index+1:,2].max()\n",
    "            Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "            continue\n",
    "    except IndexError as err1:\n",
    "        break\n",
    "    except TypeError as te:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "285ea76e-c085-4173-80ed-2657873d762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append Max_110 to the dataframe:\n",
    "Min_110 = Min_110.drop(['open','high','close'], axis=1).rename(columns={\"low\":\"price\"})\n",
    "LL_LH_df = pd.concat([LL_LH_df, Min_110], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "145a9100-732b-414c-b753-f031c5049b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-29 15:00:00</td>\n",
       "      <td>1.24283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-29 15:03:00</td>\n",
       "      <td>1.24206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-29 15:05:00</td>\n",
       "      <td>1.24231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-29 15:11:00</td>\n",
       "      <td>1.24113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-29 15:12:00</td>\n",
       "      <td>1.24152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-01-29 15:20:00</td>\n",
       "      <td>1.23988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-01-29 15:21:00</td>\n",
       "      <td>1.24069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-01-29 15:25:00</td>\n",
       "      <td>1.23943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-01-29 15:31:00</td>\n",
       "      <td>1.24019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-01-29 15:36:00</td>\n",
       "      <td>1.23930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    price\n",
       "0 2025-01-29 15:00:00  1.24283\n",
       "1 2025-01-29 15:03:00  1.24206\n",
       "2 2025-01-29 15:05:00  1.24231\n",
       "3 2025-01-29 15:11:00  1.24113\n",
       "4 2025-01-29 15:12:00  1.24152\n",
       "5 2025-01-29 15:20:00  1.23988\n",
       "6 2025-01-29 15:21:00  1.24069\n",
       "7 2025-01-29 15:25:00  1.23943\n",
       "8 2025-01-29 15:31:00  1.24019\n",
       "9 2025-01-29 15:36:00  1.23930"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LL_LH_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8073ab6-d4db-4d79-bfc2-131d3c0946c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tuple combining the list of possible p1-p2-p3 (initial values)\n",
    "p1_p2_p3i = create_tuples_p1_p3(LL_LH_df)\n",
    "\n",
    "# finding the right p1-p2-p3 in terms of ratios\n",
    "p1_p2_p3_index = []\n",
    "for i in p1_p2_p3i:\n",
    "    p3i=i[0]\n",
    "    p2i=i[1]\n",
    "    p1i=i[2]\n",
    "    p3y_p2y = LL_LH_df.iloc[p3i,1] - LL_LH_df.iloc[p2i,1]\n",
    "    p2y_p1y = LL_LH_df.iloc[p2i,1] - LL_LH_df.iloc[p1i,1]\n",
    "    p3x_p2x = LL_LH_df.iloc[p3i,0] - LL_LH_df.iloc[p2i,0]\n",
    "    p2x_p1x = LL_LH_df.iloc[p2i,0] - LL_LH_df.iloc[p1i,0]\n",
    "\n",
    "    # conditions for finding the right p1-p2-p3\n",
    "    condition1 = 1.027 <= abs(p3y_p2y/p2y_p1y) <= 1.9286\n",
    "    try:\n",
    "        condition2 = 0.217 <= abs(p3x_p2x/p2x_p1x) <= 5\n",
    "    except ZeroDivisionError as err1:\n",
    "        condition2 = False\n",
    "        \n",
    "    condition3 = p2x_p1x > pd.Timedelta(minutes=1)\n",
    "    condition4 = pd.Timedelta(minutes=2) <= p2x_p1x <= pd.Timedelta(minutes=24)\n",
    "    condition5 = pd.Timedelta(minutes=2) <= p3x_p2x <= pd.Timedelta(minutes=21)\n",
    "    condition = condition1 & condition2 & condition3 & condition4 & condition5\n",
    "    \n",
    "    if condition:\n",
    "        p1_p2_p3_index.append(i)\n",
    "\n",
    "    p1, p2, p3 = create_empty_p1_and_p2_and_p3_df()\n",
    "\n",
    "if len(p1_p2_p3_index) == 0:\n",
    "    pass\n",
    "else:\n",
    "    for p3i, p2i, p1i in p1_p2_p3_index:\n",
    "        new_p3 = LL_LH_df.iloc[[p3i]]\n",
    "        new_p2 = LL_LH_df.iloc[[p2i]]\n",
    "        new_p1 = LL_LH_df.iloc[[p1i]]\n",
    "        p3 = pd.concat([p3,new_p3], ignore_index=True)\n",
    "        p2 = pd.concat([p2,new_p2], ignore_index=True)\n",
    "        p1 = pd.concat([p1,new_p1], ignore_index=True)\n",
    "\n",
    "if len(p1) != len(p2):\n",
    "    print(\"Index error! P1 and P2 doesn't match!\")\n",
    "    \n",
    "elif Pay3 == None:\n",
    "    p1, p2, p3 = create_empty_p1_and_p2_and_p3_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcac3bc7-81c8-40db-b443-d0e5dc7244cd",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6929a1ed-1be1-49e4-812a-9801c8efb39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-29 15:25:00</td>\n",
       "      <td>1.23943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    price\n",
       "0 2025-01-29 15:25:00  1.23943"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a357a9-d312-426c-a4ee-4afecc1e9138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
