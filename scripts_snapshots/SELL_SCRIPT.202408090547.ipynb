{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0db1ccd-f4b8-41a9-8334-118e85497910",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_peaks\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mMetaTrader5\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmt5\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytz\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.signal import find_peaks\n",
    "import MetaTrader5 as mt5\n",
    "import pytz\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f34cc3-02d0-40e6-9f00-ae56d07a61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MT5 connection\n",
    "if not mt5.initialize():\n",
    "    print(\"initialize() failed, error code =\", mt5.last_error())\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffed566-2f16-475b-9075-35a4839f34bc",
   "metadata": {},
   "source": [
    "### Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69323a44-3a47-4296-8928-dc3a9dcae2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column_price_n(Pay):\n",
    "    Pa = p1_range_localminimas[p1_range_localminimas['low'] == Pay].drop(['open','high','close'], axis=1)\n",
    "    Pa = Pa.drop_duplicates(subset=['low'], keep='last')\n",
    "    Pa = Pa.rename(columns={\"low\":\"price\"})\n",
    "    return Pa\n",
    "\n",
    "def rename_column_price_x(Pay, condition):\n",
    "    Pa = p1_range_localmaximas[(p1_range_localmaximas['high'] == Pay) & condition].drop(['open','low','close'], axis=1)\n",
    "    Pa = Pa.drop_duplicates(subset=['high'], keep='last')\n",
    "    Pa = Pa.rename(columns={\"high\":\"price\"})\n",
    "    return Pa\n",
    "\n",
    "def compute_index_Pa_n(Pay):\n",
    "    Pay_index = p1_range_localminimas[p1_range_localminimas['low'] == Pay].index[-1]\n",
    "    return Pay_index\n",
    "\n",
    "def create_tuples_p1_p3(df):\n",
    "    p1_p2_p3 = []\n",
    "    max_index = df.index.max()\n",
    "    no_of_comb = ((max_index + 1) // 2) -1  # +1 to include the last element for odd lengths\n",
    "    for i in range(no_of_comb):\n",
    "        p1_p2_p3.append((max_index, max_index - 2*(i+1) + 1, max_index - 2*(i+1)))\n",
    "    return p1_p2_p3 \n",
    "\n",
    "def fetch_latest_data(OHLC_df):\n",
    "    timezone = pytz.timezone('UTC')\n",
    "    start_time = datetime.now(timezone) + timedelta(hours=3) - timedelta(minutes=5)\n",
    "    end_time = datetime.now(timezone) + timedelta(hours=3) - timedelta(minutes=1)\n",
    "    rates = mt5.copy_rates_range(symbol, timeframe, start_time, end_time)\n",
    "    new_data = pd.DataFrame(rates)\n",
    "    new_data['time'] = pd.to_datetime(new_data['time'], unit='s').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    new_data.drop([\"tick_volume\", \"spread\", \"real_volume\"], inplace=True, axis=1)\n",
    "    new_data = new_data.reindex(labels=[\"time\",\"open\", \"high\", \"low\", \"close\"], axis = 1)\n",
    "    new_data = new_data.rename(columns={\"time\":\"datetime\"})\n",
    "    new_data[\"datetime\"] = new_data[\"datetime\"].astype('<M8[ns]')\n",
    "    updated_ohlc_data = pd.concat([OHLC_df,new_data],ignore_index=True)\n",
    "    updated_ohlc_data = updated_ohlc_data.drop_duplicates(ignore_index= True)\n",
    "    updated_ohlc_data['datetime'] = updated_ohlc_data['datetime'].astype('<M8[ns]')\n",
    "    return updated_ohlc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475cbd4e-44d5-4249-a94e-3c6f749a7dd5",
   "metadata": {},
   "source": [
    "### Downloading the OHLC data from the last 7 days to 2 minutes ago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "775eccf6-8750-446e-a584-5bd5af5ecb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'EURUSD'.upper()\n",
    "timeframe = mt5.TIMEFRAME_M1\n",
    "\n",
    "#Get the time ranges in utc\n",
    "timezone = pytz.timezone('UTC')\n",
    "start_time = datetime.now(timezone) - timedelta(days=7) + timedelta(hours=3)\n",
    "end_time = datetime.now(timezone) - timedelta(minutes=2) + timedelta(hours=3)\n",
    "\n",
    "rates = mt5.copy_rates_range(symbol, timeframe, start_time, end_time)\n",
    "\n",
    "# Create a DataFrame\n",
    "rates_df = pd.DataFrame(rates)\n",
    "rates_df['time'] = pd.to_datetime(rates_df['time'], unit='s').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "rates_df.drop([\"tick_volume\", \"spread\", \"real_volume\"], inplace=True, axis=1)\n",
    "rates_df = rates_df.reindex(labels=[\"time\",\"open\", \"high\", \"low\", \"close\"], axis = 1)\n",
    "rates_df['time'] = rates_df['time'].astype('<M8[ns]')\n",
    "rates_df = rates_df.rename(columns={'time':'datetime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e933caea-003d-412e-ba68-70348337eddd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fetch_latest_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rates_df \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_latest_data\u001b[49m(rates_df)\n\u001b[1;32m      2\u001b[0m rates_df\u001b[38;5;241m.\u001b[39mtail()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fetch_latest_data' is not defined"
     ]
    }
   ],
   "source": [
    "rates_df = fetch_latest_data(rates_df)\n",
    "rates_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96eefcb-9cce-4a1d-b0ee-68d563046b78",
   "metadata": {},
   "source": [
    "### CONTINUE THIS TOMORROW\n",
    "#### IN OBTAINING THE HIGHEST POINT, THERE WILL BE A LOT OF DUPLICATES SINCE THE DATA IS FROM THE LAST 7 DAYS. \n",
    "#### FIND THE MAX POINT FROM THE LAST 1HR 21 MIN\n",
    "##### IF THE MAX POINT IS NOT MOST RECENT, WAIT FOR THE OPPORTUNITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbd0beb7-d85f-4bd0-b21f-b9a54de0511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtaining the OHLC data\n",
    "start_dt=\"2024-09-08 9:00:00\"\n",
    "end_dt=\"2024-09-08 14:00:00\"\n",
    "\n",
    "rates_df = OHLC_df[(OHLC_df['datetime'] >= start_dt) & (OHLC_df['datetime'] <= end_dt)]\n",
    "\n",
    "#OBTAINING THE HIGHEST POINT DURING THE NY SESSION\n",
    "p3y = rates_df['high'].max()\n",
    "\n",
    "#OBTAINING THE INDEX OF THE HIGHEST POINT\n",
    "p3i = (rates_df[rates_df['high']== p3y])\n",
    "\n",
    "#obtaining the OHLC data of P3\n",
    "p3 = p3i.iloc[[-1]]\n",
    "\n",
    "#converting the datatype of the datetime column\n",
    "rates_df.loc[:,'datetime'] = pd.to_datetime(rates_df[\"datetime\"])\n",
    "\n",
    "#obtaining the data within the time limit 4 to 45 mins before P3\n",
    "p1x_range_1 = p3[\"datetime\"].iloc[0] - timedelta(minutes = 45)\n",
    "p1x_range_2 = p3[\"datetime\"].iloc[0] - timedelta(minutes = 0)\n",
    "mask1= rates_df[\"datetime\"].ge(p1x_range_1) & rates_df[\"datetime\"].le(p1x_range_2)\n",
    "p1_range = rates_df[mask1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812dce37-aaed-4569-a9aa-ca4653d7a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of local maximas\n",
    "local_maximas_i,_ = find_peaks(p1_range['high'].values)\n",
    "local_maximas_i = np.array(local_maximas_i)\n",
    "\n",
    "# Find the index of the local minima by inverting the data\n",
    "local_minimas_i,_ = find_peaks(-p1_range['low'].values)\n",
    "local_minimas_i = np.array(local_minimas_i)\n",
    "\n",
    "#Obtaining the dataframe of the local minimas and local maximas\n",
    "p1_range_localminimas = p1_range[p1_range.index.isin(local_minimas_i)].reset_index(drop=True)\n",
    "p1_range_localmaximas = p1_range[p1_range.index.isin(local_maximas_i)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "830d6511-b94b-403a-a148-2c60532762f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the value of Pay1\n",
    "Pay1 = p1_range_localminimas[\"low\"].min()\n",
    "\n",
    "#Finding the index of the first local minima\n",
    "Pay1_index = p1_range_localminimas[p1_range_localminimas['low'] == Pay1].index.min()\n",
    "\n",
    "\n",
    "#Dropping the minimas before the first local minimas\n",
    "mask = p1_range_localminimas.index >= Pay1_index\n",
    "p1_range_localminimas = p1_range_localminimas[mask].reset_index(drop=True)\n",
    "p1_range_localminimas\n",
    "#Finding the index of the first local minima\n",
    "Pay1_index = compute_index_Pa_n(Pay1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a7ff70-fddf-4b25-b9b4-c9cc88db05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the y value of the possible 2nd local minima:\n",
    "Pay3 = p1_range_localminimas.iloc[Pay1_index+1:,3].min()\n",
    "Pay3_index = compute_index_Pa_n(Pay3)\n",
    "Pay3_index_range = Pay3_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79242a20-1dd1-4d7f-8102-6d50f9d3b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0966\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        #finding the index of the 1st local maxima\n",
    "        condition1 = p1_range_localmaximas[\"datetime\"].ge(p1_range_localminimas.iloc[Pay1_index,0])\n",
    "        condition2 = p1_range_localmaximas[\"datetime\"].le(p1_range_localminimas.iloc[Pay3_index,0])\n",
    "        condition = condition1 & condition2\n",
    "        \n",
    "        #to find the y value of the 1st local maxima:\n",
    "        Pay2 = p1_range_localmaximas[condition == True]['high'].values\n",
    "        if len(Pay2) == 0:\n",
    "            #proceed with the next pay3 index and rerun the while loop\n",
    "            Pay3_index = Pay3_index+1\n",
    "            Pay3 = p1_range_localminimas.iloc[Pay3_index:,3].min()\n",
    "            print(Pay3)\n",
    "            continue\n",
    "        else:\n",
    "            Pay2=Pay2.max()\n",
    "            break\n",
    "    except IndexError as err1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fad12e29-9449-4af6-926b-8e48a02ccc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a new dataframe of the higher highs and higher lows approaching P3 in chronological order\n",
    "HH_HL_df = pd.DataFrame(columns=['datetime','price'])\n",
    "HH_HL_df = pd.DataFrame({'datetime': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "\n",
    "#Grabbing the data attached to Pay*\n",
    "HH_HL_df = pd.concat([HH_HL_df, rename_column_price_n(Pay1)], ignore_index=True)\n",
    "\n",
    "Pa2 = p1_range_localmaximas[p1_range_localmaximas['high'] == Pay2].drop(['open','low','close'], axis=1)\n",
    "Pa2 = Pa2.drop_duplicates(subset=['high'], keep='last')\n",
    "Pa2 = Pa2.rename(columns={\"high\":\"price\"})\n",
    "HH_HL_df = pd.concat([HH_HL_df, Pa2], ignore_index=True)\n",
    "\n",
    "HH_HL_df = pd.concat([HH_HL_df, rename_column_price_n(Pay3)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d892b7a-aedf-4a73-8ce2-df71240200c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resetting the values to avoid issues\n",
    "Pay2 = Pay1_index = Pay3_index = 0\n",
    "\n",
    "#Assigning new values to find new sets of Pa2, Pa3\n",
    "Pay1 = Pay3\n",
    "Pay1_index = compute_index_Pa_n(Pay1)\n",
    "\n",
    "#Resetting the values to avoid issues\n",
    "Pay3 = Pay3_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "742a1e7d-475b-48e8-8252-139b8e32e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the initial value of Pay3\n",
    "Pay3 = p1_range_localminimas.iloc[Pay1_index+1:,3].min()\n",
    "Pay3_index = compute_index_Pa_n(Pay3)\n",
    "\n",
    "\n",
    "#Finding the values of the higher lows and higher highs and appending it to the HH_HL_df\n",
    "while True:\n",
    "    Pay3_index_range = 0\n",
    "    try:\n",
    "        # Check if the current Pay3_index is beyond the end of p1_range_localminimas\n",
    "        if Pay3_index > len(p1_range_localminimas):\n",
    "            print(f\"End of p1_range_localminimas reached.{Pay3_index}\")\n",
    "            break\n",
    "            \n",
    "        #finding the index of the next local maxima\n",
    "        condition1 = p1_range_localmaximas[\"datetime\"].ge(p1_range_localminimas.iloc[Pay1_index,0])\n",
    "        condition2 = p1_range_localmaximas[\"datetime\"].le(p1_range_localminimas.iloc[Pay3_index,0])\n",
    "        condition = condition1 & condition2\n",
    "\n",
    "        \n",
    "        #to find the y value of the next local maxima:\n",
    "        Pay2 = p1_range_localmaximas[condition == True]['high'].values\n",
    "        \n",
    "        #previous HH index\n",
    "        pHH_index = HH_HL_df[HH_HL_df['price'] == Pay1].index[0] - 1\n",
    "        pHHy = HH_HL_df.iloc[pHH_index,1]\n",
    "\n",
    "        #if Pay2 isnt existing for the current Pay3\n",
    "        condition3 = len(Pay2) == 0\n",
    "        \n",
    "        #if the current Pay2 is less than the previous HH\n",
    "        try:\n",
    "            condition4 = p1_range_localmaximas[condition == True]['high'].values.max() < pHHy\n",
    "        except ValueError as err2:\n",
    "            Pay3_index = Pay3_index+1\n",
    "            Pay3 = p1_range_localminimas.iloc[Pay3_index:,3].min()\n",
    "            Pay3_index = compute_index_Pa_n(Pay3)\n",
    "            continue\n",
    "        if condition3 or condition4:\n",
    "            #proceed with the next pay3 index and rerun the while loop\n",
    "            Pay2 = 0\n",
    "            Pay3_index_range = Pay3_index+1\n",
    "            Pay3 = p1_range_localminimas.iloc[Pay3_index_range:,3].min()\n",
    "            Pay3_index = compute_index_Pa_n(Pay3)\n",
    "            continue\n",
    "        else:\n",
    "            Pay2=Pay2.max()\n",
    "            #Appending to the HH_HL_df \n",
    "            condition5 = (p1_range_localmaximas['high'] == Pay2) & condition\n",
    "            HH_HL_df = pd.concat([HH_HL_df, rename_column_price_x(Pay2, condition5)], ignore_index=True)\n",
    "            HH_HL_df = pd.concat([HH_HL_df, rename_column_price_n(Pay3)], ignore_index=True)\n",
    "            \n",
    "            #Assigning new values to find new sets of Pa2, Pa3\n",
    "            Pay1 = Pay3\n",
    "            Pay1_index = compute_index_Pa_n(Pay1)\n",
    "            \n",
    "            #Finding the initial value of Pay3\n",
    "            Pay3 = p1_range_localminimas.iloc[Pay1_index+1:,3].min()\n",
    "            Pay3_index = compute_index_Pa_n(Pay3)\n",
    "            continue\n",
    "    except IndexError as err1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "362a1118-8339-4902-b05a-17c9ac4cfa01",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Append p3 to the dataframe:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m p3 \u001b[38;5;241m=\u001b[39m p3\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m p3 \u001b[38;5;241m=\u001b[39m p3\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m      4\u001b[0m HH_HL_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([HH_HL_df, p3], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p3' is not defined"
     ]
    }
   ],
   "source": [
    "#Append p3 to the dataframe:\n",
    "p3 = p3.drop(['open','low','close'], axis=1)\n",
    "p3 = p3.rename(columns={\"high\":\"price\"})\n",
    "HH_HL_df = pd.concat([HH_HL_df, p3], ignore_index=True)\n",
    "\n",
    "# Create a tuple combining the list of possible p1-p2-p3 (initial values)\n",
    "p1_p2_p3i = create_tuples_p1_p3(HH_HL_df)\n",
    "p1_p2_p3i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7808b51-b33e-4709-a50c-04229e87bd71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p1_p2_p3i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# finding the right p1-p2-p3 in terms of ratios\u001b[39;00m\n\u001b[1;32m      3\u001b[0m p1_p2_p3_index \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m p1_p2_p3i:\n\u001b[1;32m      5\u001b[0m     p3i\u001b[38;5;241m=\u001b[39mi[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m     p2i\u001b[38;5;241m=\u001b[39mi[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p1_p2_p3i' is not defined"
     ]
    }
   ],
   "source": [
    "# finding the right p1-p2-p3 in terms of ratios\n",
    "\n",
    "p1_p2_p3_index = []\n",
    "for i in p1_p2_p3i:\n",
    "    p3i=i[0]\n",
    "    p2i=i[1]\n",
    "    p1i=i[2]\n",
    "    p3y_p2y = HH_HL_df.iloc[p3i,1] - HH_HL_df.iloc[p2i,1]\n",
    "    p2y_p1y = HH_HL_df.iloc[p2i,1] - HH_HL_df.iloc[p1i,1]\n",
    "    p3x_p2x = HH_HL_df.iloc[p3i,0] - HH_HL_df.iloc[p2i,0]\n",
    "    p2x_p1x = HH_HL_df.iloc[p2i,0] - HH_HL_df.iloc[p1i,0]\n",
    "\n",
    "    # conditions for finding the right p1-p2-p3\n",
    "    condition1 = 1.027 < abs(p3y_p2y/p2y_p1y) < 2.337\n",
    "    condition2 = 0.333 < p3x_p2x/p2x_p1x < 5\n",
    "    condition3 = p2x_p1x > pd.Timedelta(minutes=1)\n",
    "    condition4 = pd.Timedelta(minutes=2) < p2x_p1x < pd.Timedelta(minutes=24)\n",
    "    condition5 = pd.Timedelta(minutes=2) < p2x_p1x < pd.Timedelta(minutes=21)\n",
    "    condition = condition1 & condition2 & condition3 & condition4 & condition5\n",
    "    \n",
    "    if condition:\n",
    "        p1_p2_p3_index.append(i)\n",
    "        print(p1_p2_p3_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7031f7d-1fde-461d-818f-21e0eaf10bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe52054f-76e8-43f6-9eb1-2957f850b780",
   "metadata": {},
   "source": [
    "# Values for Testing Purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "680c5845-b7a1-4604-a059-6aed0317b156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-05 15:07:00</td>\n",
       "      <td>1.09647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-05 15:10:00</td>\n",
       "      <td>1.09694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-08-05 15:21:00</td>\n",
       "      <td>1.09660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-08-05 15:25:00</td>\n",
       "      <td>1.09747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-08-05 15:32:00</td>\n",
       "      <td>1.09671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-08-05 15:41:00</td>\n",
       "      <td>1.09844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-08-05 15:42:00</td>\n",
       "      <td>1.09801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-08-05 15:49:00</td>\n",
       "      <td>1.10084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime    price\n",
       "0 2024-08-05 15:07:00  1.09647\n",
       "1 2024-08-05 15:10:00  1.09694\n",
       "2 2024-08-05 15:21:00  1.09660\n",
       "3 2024-08-05 15:25:00  1.09747\n",
       "4 2024-08-05 15:32:00  1.09671\n",
       "5 2024-08-05 15:41:00  1.09844\n",
       "6 2024-08-05 15:42:00  1.09801\n",
       "7 2024-08-05 15:49:00  1.10084"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#previous HH index\n",
    "HH_HL_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdcf908-2bb4-4080-96c5-384581738dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
