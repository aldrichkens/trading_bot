{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0038cf8-4a0f-41d5-970b-3dae9b9a9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone, date\n",
    "from scipy.signal import find_peaks\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a03e725-05f7-4509-8d5d-0cab12474c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions of the sell diagram ratio module\n",
    "\n",
    "def convert_minima_to_HH_HL_df(Pay, p1_range_localminimas):\n",
    "    Pa = p1_range_localminimas[p1_range_localminimas['low'] == Pay].drop(['open','high','close'], axis=1)\n",
    "    Pa = Pa.drop_duplicates(subset=['low'], keep='last')\n",
    "    Pa = Pa.rename(columns={\"low\":\"price\"})\n",
    "    return Pa\n",
    "\n",
    "def convert_maxima_to_HH_HL_df(Pay, condition, p1_range_localmaximas):\n",
    "    Pa = p1_range_localmaximas[(p1_range_localmaximas['high'] == Pay) & condition].drop(['open','low','close'], axis=1)  \n",
    "    Pa = Pa.drop_duplicates(subset=['high'], keep='last')\n",
    "    Pa = Pa.rename(columns={\"high\":\"price\"})\n",
    "    return Pa\n",
    "\n",
    "def compute_index_Pa_n(Pay, p1_range_localminimas):\n",
    "    try:\n",
    "        Pay_index = p1_range_localminimas[p1_range_localminimas['low'] == Pay].index[-1]\n",
    "    except IndexError as IE:\n",
    "        Pay_index = None\n",
    "    return Pay_index\n",
    "\n",
    "\n",
    "def create_tuples_p1_p3(df):\n",
    "    p1_p2_p3 = []\n",
    "    max_index = df.index.max()\n",
    "    no_of_comb = ((max_index + 1) // 2) -1  # +1 to include the last element for odd lengths\n",
    "    for i in range(no_of_comb):\n",
    "        p1_p2_p3.append((max_index, max_index - 2*(i+1) + 1, max_index - 2*(i+1)))\n",
    "    return p1_p2_p3\n",
    "\n",
    "def create_empty_p1_and_p2_and_p3_df():\n",
    "    p1 = pd.DataFrame(columns=['time','price'])\n",
    "    p1 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    p2 = pd.DataFrame(columns=['time','price'])\n",
    "    p2 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    p3 = pd.DataFrame(columns=['time','price'])\n",
    "    p3 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    return p1, p2, p3\n",
    "\n",
    "def create_empty_time_price_df():\n",
    "    df = pd.DataFrame(columns=['time','price'])\n",
    "    df = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    return df\n",
    "\n",
    "def create_empty_time_open_high_low_close_df():\n",
    "    df = pd.DataFrame(columns=['time','open','high','low','close'])\n",
    "    df = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'open': pd.Series(dtype='float'),\n",
    "                      'high': pd.Series(dtype='float'), 'low': pd.Series(dtype='float'),\n",
    "                      'close': pd.Series(dtype='float')})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c3d8d-30ef-4351-a35e-0ac72262797b",
   "metadata": {},
   "source": [
    "### START OF FAKE VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b528dc68-4290-4d8f-a33e-a2345a6e6f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>2025-01-17 03:51:00</td>\n",
       "      <td>2713.62</td>\n",
       "      <td>2713.79</td>\n",
       "      <td>2713.24</td>\n",
       "      <td>2713.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>2025-01-17 03:52:00</td>\n",
       "      <td>2713.64</td>\n",
       "      <td>2714.05</td>\n",
       "      <td>2713.51</td>\n",
       "      <td>2714.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>2025-01-17 03:53:00</td>\n",
       "      <td>2714.03</td>\n",
       "      <td>2714.48</td>\n",
       "      <td>2713.98</td>\n",
       "      <td>2714.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>2025-01-17 03:54:00</td>\n",
       "      <td>2714.63</td>\n",
       "      <td>2714.77</td>\n",
       "      <td>2713.48</td>\n",
       "      <td>2713.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>2025-01-17 03:55:00</td>\n",
       "      <td>2713.57</td>\n",
       "      <td>2714.26</td>\n",
       "      <td>2713.57</td>\n",
       "      <td>2713.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>2025-01-17 05:04:00</td>\n",
       "      <td>2716.50</td>\n",
       "      <td>2717.02</td>\n",
       "      <td>2716.32</td>\n",
       "      <td>2716.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>2025-01-17 05:05:00</td>\n",
       "      <td>2717.05</td>\n",
       "      <td>2717.09</td>\n",
       "      <td>2716.79</td>\n",
       "      <td>2716.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>2025-01-17 05:06:00</td>\n",
       "      <td>2716.70</td>\n",
       "      <td>2717.00</td>\n",
       "      <td>2716.65</td>\n",
       "      <td>2716.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2025-01-17 05:07:00</td>\n",
       "      <td>2716.74</td>\n",
       "      <td>2716.98</td>\n",
       "      <td>2716.71</td>\n",
       "      <td>2716.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>2025-01-17 05:08:00</td>\n",
       "      <td>2716.87</td>\n",
       "      <td>2717.38</td>\n",
       "      <td>2716.68</td>\n",
       "      <td>2716.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time     open     high      low    close\n",
       "650 2025-01-17 03:51:00  2713.62  2713.79  2713.24  2713.49\n",
       "651 2025-01-17 03:52:00  2713.64  2714.05  2713.51  2714.01\n",
       "652 2025-01-17 03:53:00  2714.03  2714.48  2713.98  2714.48\n",
       "653 2025-01-17 03:54:00  2714.63  2714.77  2713.48  2713.73\n",
       "654 2025-01-17 03:55:00  2713.57  2714.26  2713.57  2713.80\n",
       "..                  ...      ...      ...      ...      ...\n",
       "723 2025-01-17 05:04:00  2716.50  2717.02  2716.32  2716.98\n",
       "724 2025-01-17 05:05:00  2717.05  2717.09  2716.79  2716.83\n",
       "725 2025-01-17 05:06:00  2716.70  2717.00  2716.65  2716.70\n",
       "726 2025-01-17 05:07:00  2716.74  2716.98  2716.71  2716.85\n",
       "727 2025-01-17 05:08:00  2716.87  2717.38  2716.68  2716.81\n",
       "\n",
       "[78 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fake Values only in here since this is backtest\n",
    "\n",
    "#Fake Values only in here since this is backtest\n",
    "sell_tp = 0\n",
    "buy_tp = 1000\n",
    "#Importing the CSV file\n",
    "path = f\"./OHLC_data/XAUUSD_20250117_20250120.csv\"\n",
    "OHLC_df = pd.read_csv(path)\n",
    "OHLC_df['time'] = pd.to_datetime(OHLC_df['time'], format='%Y-%m-%d %H:%M:%S')\n",
    "# DATA TO BE TESTED\n",
    "mask = (OHLC_df[\"time\"] >= \"2025-01-17 03:51:00\") & (OHLC_df[\"time\"] <= \"2025-01-17 06:47:00\")\n",
    "rates_frame = OHLC_df[mask]\n",
    "Last_110 = OHLC_df[mask].tail(110)\n",
    "MaxHighPrice = Last_110[\"high\"].max()\n",
    "MinLowPrice = Last_110[\"low\"].min()\n",
    "MaxHighPoint = Last_110[Last_110[\"high\"] == MaxHighPrice].iloc[[0]]\n",
    "MinLowPoint = Last_110[Last_110[\"low\"] == MinLowPrice].iloc[[0]]\n",
    "MaxHighTime = MaxHighPoint['time'].iloc[0]\n",
    "MinLowTime = MinLowPoint['time'].iloc[0]\n",
    "rates_frame_p3 = rates_frame[rates_frame[\"time\"]<= MaxHighTime].tail(110)\n",
    "p3_rates_frame = rates_frame[rates_frame[\"time\"]>= MaxHighTime]\n",
    "rates_frame_p3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975e59b-8371-4d41-878d-0f116d1b19cd",
   "metadata": {},
   "source": [
    "### END OF FAKE VALUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9131b692-0c4d-4dcc-9506-9f93c2a21488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FUNCTION TO DETECT P1 P2 P3 for the EXTERNAL AND INTERNAL\n",
    "def obtain_p1_p2_p3(rates_frame_p3):\n",
    "    #obtaining the maximum point from the last 110 minutes for sells\n",
    "    Max_110_y = rates_frame_p3[\"high\"].max()\n",
    "    Max_110 = rates_frame_p3[rates_frame_p3[\"high\"] == Max_110_y].iloc[[-1]]\n",
    "    \n",
    "    #obtaining the minimum point from the last 110 minutes for sells\n",
    "    Min_110_y = rates_frame_p3[\"low\"].min()\n",
    "    Min_110 = rates_frame_p3[rates_frame_p3[\"low\"] == Min_110_y].iloc[[-1]]\n",
    "    \n",
    "    # Creating a new dataframe for the start and end of the minimum points in order to grab the data of local maxima and minima in an uptrend\n",
    "    p1_range_start_time = Min_110[\"time\"].iloc[-1]\n",
    "    p1_range_end_time = Max_110['time'].iloc[-1]\n",
    "    mask = rates_frame_p3[\"time\"].ge(p1_range_start_time) & rates_frame_p3[\"time\"].le(p1_range_end_time)\n",
    "    p1_range = rates_frame_p3[mask].reset_index(drop=True)\n",
    "    \n",
    "    # Find the index of local maximas\n",
    "    local_maximas_i,_ = find_peaks(p1_range['high'].values)\n",
    "    local_maximas_i = np.array(local_maximas_i)\n",
    "    \n",
    "    # Find the index of the local minima by inverting the data\n",
    "    local_minimas_i,_ = find_peaks(-p1_range['low'].values)\n",
    "    local_minimas_i = np.array(local_minimas_i)\n",
    "    \n",
    "    #Obtaining the dataframe of the local minimas and local maximas\n",
    "    p1_range_localminimas = p1_range[p1_range.index.isin(local_minimas_i)].reset_index(drop=True)\n",
    "    p1_range_localmaximas = p1_range[p1_range.index.isin(local_maximas_i)].reset_index(drop=True)\n",
    "    \n",
    "    # Finding the value of Pay1\n",
    "    Pay1 = Min_110_y\n",
    "    \n",
    "    #to find the y value of the possible 2nd local minima:\n",
    "    Pay3 = p1_range_localminimas[\"low\"].min()\n",
    "\t\n",
    "    Pay3_index = compute_index_Pa_n(Pay3, p1_range_localminimas)\n",
    "    Pay3_index_range = Pay3_index\n",
    "    \n",
    "    while True:\n",
    "        #finding the index of the 1st local maxima in the series \"p1_range_localmaximas\" as P2\n",
    "        condition1 = p1_range_localmaximas[\"time\"].ge(p1_range.iloc[0,0])\n",
    "        condition2 = p1_range_localmaximas[\"time\"].le(p1_range_localminimas.iloc[Pay3_index,0])\n",
    "        condition = condition1 & condition2\n",
    "        \n",
    "        Pay2 = p1_range_localmaximas[condition == True]['high'].values\n",
    "\t\n",
    "        try:\n",
    "            #finding the index of the 1st local maxima in the series \"p1_range_localmaxima\" as P2\n",
    "            condition1 = p1_range_localmaximas[\"time\"].ge(p1_range.iloc[0,0])\n",
    "            condition2 = p1_range_localmaximas[\"time\"].le(p1_range_localminimas.iloc[Pay3_index,0])\n",
    "            condition = condition1 & condition2\n",
    "            \n",
    "            #to find the y value of the 1st local maxima:\n",
    "            Pay2 = p1_range_localmaximas[condition == True]['high'].values\n",
    "            if len(Pay2) == 0:\n",
    "                #proceed with the next pay3 index and rerun the while loop\n",
    "                Pay3_index_range = Pay3_index_range + 1\n",
    "                Pay3 = p1_range_localminimas.iloc[Pay3_index_range:,3].min()\n",
    "                Pay3_index = compute_index_Pa_n(Pay3, p1_range_localminimas)\n",
    "                continue\n",
    "            else:\n",
    "                #if value exists, find the maximum\n",
    "                Pay2 = max(Pay2)\n",
    "                break\n",
    "        except IndexError as err1:\n",
    "            break\n",
    "        except ValueError as ve:\n",
    "            break\n",
    "        except TypeError as te:\n",
    "            break\n",
    "    \n",
    "            \n",
    "    #Making a new dataframe of the higher highs and higher lows approaching P3 in chronological order\n",
    "    HH_HL_df = create_empty_time_price_df()\n",
    "    \n",
    "    #Grabbing the data attached to Pay*\n",
    "    mask = rates_frame_p3['low'] == Pay1\n",
    "    pa1 = rates_frame_p3[mask].drop(['open','high','close'], axis=1).drop_duplicates(subset=['low'], keep='last').rename(columns={\"low\":\"price\"})\n",
    "    HH_HL_df = pd.concat([HH_HL_df, pa1], ignore_index=True)\n",
    "    \n",
    "    Pa2 = p1_range_localmaximas[p1_range_localmaximas['high'] == Pay2].drop(['open','low','close'], axis=1)\n",
    "    Pa2 = Pa2.drop_duplicates(subset=['high'], keep='last')\n",
    "    Pa2 = Pa2.rename(columns={\"high\":\"price\"})\n",
    "    HH_HL_df = pd.concat([HH_HL_df, Pa2], ignore_index=True)\n",
    "    HH_HL_df = pd.concat([HH_HL_df, convert_minima_to_HH_HL_df(Pay3, p1_range_localminimas)], ignore_index=True)\n",
    "    \n",
    "    #Resetting the values to avoid issues\n",
    "    Pay2 = Pay1_index = Pay3_index = 0\n",
    "    \n",
    "    #Assigning new values to find new sets of Pa2, Pa3\n",
    "    Pay1 = Pay3\n",
    "    Pay1_index = compute_index_Pa_n(Pay1, p1_range_localminimas)\n",
    "    \n",
    "    #Resetting the values to avoid issues\n",
    "    Pay3 = Pay3_index = 0\n",
    "    \n",
    "    #Finding the initial value of Pay3\n",
    "    try:\n",
    "        Pay3 = p1_range_localminimas.iloc[Pay1_index+1:,3].min()\n",
    "        Pay3_index = compute_index_Pa_n(Pay3, p1_range_localminimas)\n",
    "    except IndexError as err1:\n",
    "        print('There is no next p3. Continue with the external P1-P2-P3...')\n",
    "        Pay3 = None\n",
    "\n",
    "    if Pay3 != None:\n",
    "        #Finding the values of the higher lows and higher highs and appending it to the HH_HL_df\n",
    "        while True:\n",
    "            Pay3_index_range = 0\n",
    "            try:\n",
    "                # Check if the current Pay3_index is beyond the end of p1_range_localminimas\n",
    "                if Pay3_index > len(p1_range_localminimas):\n",
    "                    print(f\"End of p1_range_localminimas reached.{Pay3_index}\")\n",
    "                    break\n",
    "                    \n",
    "                #finding the index of the next local maxima\n",
    "                condition1 = p1_range_localmaximas[\"time\"].ge(p1_range_localminimas.iloc[Pay1_index,0])\n",
    "                condition2 = p1_range_localmaximas[\"time\"].le(p1_range_localminimas.iloc[Pay3_index,0])\n",
    "                condition = condition1 & condition2\n",
    "        \n",
    "                \n",
    "                #to find the y value of the next local maxima:\n",
    "                Pay2 = p1_range_localmaximas[condition == True]['high'].values\n",
    "                \n",
    "                #previous HH index\n",
    "                pHH_index = HH_HL_df[HH_HL_df['price'] == Pay1].index[0] - 1\n",
    "                pHHy = HH_HL_df.iloc[pHH_index,1]\n",
    "        \n",
    "                #if Pay2 isnt existing for the current Pay3\n",
    "                condition3 = len(Pay2) == 0\n",
    "                \n",
    "                #if the current Pay2 is less than the previous HH\n",
    "                try:\n",
    "                    condition4 = p1_range_localmaximas[condition == True]['high'].values.max() < pHHy\n",
    "                except ValueError as err2:\n",
    "                    Pay3_index = Pay3_index+1\n",
    "                    Pay3 = p1_range_localminimas.iloc[Pay3_index:,3].min()\n",
    "                    Pay3_index = compute_index_Pa_n(Pay3, p1_range_localminimas)\n",
    "                    continue\n",
    "                    \n",
    "                if condition3 or condition4:\n",
    "                    #proceed with the next pay3 index and rerun the while loop\n",
    "                    Pay2 = 0\n",
    "                    Pay3_index_range = Pay3_index+1\n",
    "                    Pay3 = p1_range_localminimas.iloc[Pay3_index_range:,3].min()\n",
    "                    Pay3_index = compute_index_Pa_n(Pay3, p1_range_localminimas)\n",
    "                    continue\n",
    "                else:\n",
    "                    Pay2=Pay2.max()\n",
    "                    #Appending to the HH_HL_df \n",
    "                    condition5 = (p1_range_localmaximas['high'] == Pay2) & condition\n",
    "                    HH_HL_df = pd.concat([HH_HL_df, convert_maxima_to_HH_HL_df(Pay2, condition5, p1_range_localmaximas)], ignore_index=True)\n",
    "                    HH_HL_df = pd.concat([HH_HL_df, convert_minima_to_HH_HL_df(Pay3, p1_range_localminimas)], ignore_index=True)\n",
    "                    \n",
    "                    #Assigning new values to find new sets of Pa2, Pa3\n",
    "                    Pay1 = Pay3\n",
    "                    Pay1_index = compute_index_Pa_n(Pay1, p1_range_localminimas)\n",
    "                    \n",
    "                    #Finding the initial value of Pay3\n",
    "                    Pay3 = p1_range_localminimas.iloc[Pay1_index+1:,3].min()\n",
    "                    Pay3_index = compute_index_Pa_n(Pay3, p1_range_localminimas)\n",
    "                    continue\n",
    "            except IndexError as err1:\n",
    "                break\n",
    "            except TypeError as te:\n",
    "                break\n",
    "    \n",
    "    \n",
    "        #Append Max_110 to the dataframe:\n",
    "        Max_110 = Max_110.drop(['open','low','close'], axis=1).rename(columns={\"high\":\"price\"})\n",
    "        HH_HL_df = pd.concat([HH_HL_df, Max_110], ignore_index=True)\n",
    "        \n",
    "        # Create a tuple combining the list of possible p1-p2-p3 (initial values)\n",
    "        p1_p2_p3i = create_tuples_p1_p3(HH_HL_df)\n",
    "        \n",
    "        # finding the right p1-p2-p3 in terms of ratios\n",
    "        p1_p2_p3_index = []\n",
    "        for i in p1_p2_p3i:\n",
    "            p3i=i[0]\n",
    "            p2i=i[1]\n",
    "            p1i=i[2]\n",
    "            p3y_p2y = HH_HL_df.iloc[p3i,1] - HH_HL_df.iloc[p2i,1]\n",
    "            p2y_p1y = HH_HL_df.iloc[p2i,1] - HH_HL_df.iloc[p1i,1]\n",
    "            p3x_p2x = HH_HL_df.iloc[p3i,0] - HH_HL_df.iloc[p2i,0]\n",
    "            p2x_p1x = HH_HL_df.iloc[p2i,0] - HH_HL_df.iloc[p1i,0]\n",
    "        \n",
    "            # conditions for finding the right p1-p2-p3\n",
    "            condition1 = 1.027 <= abs(p3y_p2y/p2y_p1y) <= 1.9286\n",
    "            try:\n",
    "                condition2 = 0.217 <= abs(p3x_p2x/p2x_p1x) <= 5\n",
    "            except ZeroDivisionError as err1:\n",
    "                condition2 = False\n",
    "                \n",
    "            condition3 = p2x_p1x > pd.Timedelta(minutes=1)\n",
    "            condition4 = pd.Timedelta(minutes=2) <= p2x_p1x <= pd.Timedelta(minutes=24)\n",
    "            condition5 = pd.Timedelta(minutes=2) <= p3x_p2x <= pd.Timedelta(minutes=21)\n",
    "            condition = condition1 & condition2 & condition3 & condition4 & condition5\n",
    "            \n",
    "            if condition:\n",
    "                p1_p2_p3_index.append(i)\n",
    "\n",
    "            p1, p2, p3 = create_empty_p1_and_p2_and_p3_df()\n",
    "        \n",
    "        if len(p1_p2_p3_index) == 0:\n",
    "            return p1_range_localminimas, p1_range_localmaximas, HH_HL_df, p1, p2, p3\n",
    "            \n",
    "        else:\n",
    "            for p3i, p2i, p1i in p1_p2_p3_index:\n",
    "                new_p3 = HH_HL_df.iloc[[p3i]]\n",
    "                new_p2 = HH_HL_df.iloc[[p2i]]\n",
    "                new_p1 = HH_HL_df.iloc[[p1i]]\n",
    "                p3 = pd.concat([p3,new_p3], ignore_index=True)\n",
    "                p2 = pd.concat([p2,new_p2], ignore_index=True)\n",
    "                p1 = pd.concat([p1,new_p1], ignore_index=True)\n",
    "                return  p1_range_localminimas, p1_range_localmaximas, HH_HL_df, p1, p2, p3\n",
    "        \n",
    "        if len(p1) != len(p2):\n",
    "            print(\"Index error! P1 and P2 doesn't match!\")\n",
    "            return p1_range_localminimas, p1_range_localmaximas, HH_HL_df, p1, p2, p3\n",
    "            \n",
    "    elif Pay3 == None:\n",
    "        p1, p2, p3 = create_empty_p1_and_p2_and_p3_df()\n",
    "        return p1_range_localminimas, p1_range_localmaximas, HH_HL_df, p1, p2, p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44ccc27f-6d19-4fdd-b882-bd9dccba3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_sell(rates_frame_p3, p3_rates_frame, sell_tp):\n",
    "    TP1_price = None\n",
    "    # OBTAINING THE EXTERNAL p1-p2-p3\n",
    "    (\n",
    "        p1_range_localminimas,\n",
    "        p1_range_localmaximas,\n",
    "        HH_HL_df,\n",
    "        p1,\n",
    "        p2,\n",
    "        p3\n",
    "    ) = obtain_p1_p2_p3(rates_frame_p3)\n",
    "\n",
    "    \n",
    "    # FINDING THE VALUES OF THE OHLC DATAFRAME FROM THE EXTERNAL P2 AND P3 to HAVE THE INTERNAL P1-P2-P3\n",
    "    if not len(p1) == 0 and not len(p2) == 0:\n",
    "        p1_internal_range_start_time = p2[\"time\"].iloc[-1]\n",
    "        p1_internal_range_end_time = p3[\"time\"].iloc[-1]\n",
    "        \n",
    "        mask = (p1_internal_range_start_time <= rates_frame_p3[\"time\"]) & (rates_frame_p3[\"time\"] <= p1_internal_range_end_time)\n",
    "        p1_internal_range = rates_frame_p3[mask]\n",
    "        \n",
    "    try: \n",
    "        (\n",
    "            p1_range_localminimas_internal,\n",
    "            p1_range_localmaximas_internal,\n",
    "            HH_HL_df_internal, p1_internal,\n",
    "            p2_internal,\n",
    "            p3_internal\n",
    "        ) = obtain_p1_p2_p3(p1_internal_range)\n",
    "    except (TypeError, ValueError) as TE_VE:\n",
    "        p1_internal, p2_internal, p3_internal = create_empty_p1_and_p2_and_p3_df()\n",
    "        p1_range_localminimas_internal = p1_range_localmaximas_internal = create_empty_time_open_high_low_close_df()\n",
    "        HH_HL_df_internal = create_empty_time_price_df()\n",
    "    except UnboundLocalError as ULE:\n",
    "        #if there is no p1-p2-p3 because of the time limits, it will return a ULE, therefore, find the p1-p2-p3 with another dataframe\n",
    "        #tail 42 is just temporary, gather more data for this\n",
    "        p1_internal_range = rates_frame_p3.tail(42)\n",
    "\n",
    "        try:\n",
    "            (\n",
    "                p1_range_localminimas_internal,\n",
    "                p1_range_localmaximas_internal,\n",
    "                HH_HL_df_internal, p1_internal,\n",
    "                p2_internal,\n",
    "                p3_internal\n",
    "            ) = obtain_p1_p2_p3(p1_internal_range)\n",
    "        except (TypeError, UnboundLocalError) as TE_ULE:\n",
    "            p1_internal, p2_internal, p3_internal = create_empty_p1_and_p2_and_p3_df()\n",
    "            p1_range_localminimas_internal = p1_range_localmaximas_internal = create_empty_time_open_high_low_close_df()\n",
    "            HH_HL_df_internal = create_empty_time_price_df()\n",
    "        \n",
    "            \n",
    "    \n",
    "\t# APPEND THE VALUES OF THE INTERNAL P1, P2, P3 to the external one. \n",
    "    p1 = pd.concat([p1,p1_internal], ignore_index=True)\n",
    "    p2 = pd.concat([p2,p2_internal], ignore_index=True)\n",
    "    p3 = pd.concat([p3,p3_internal], ignore_index=True)\n",
    "    \n",
    "    #SETTING THE INITIAL VALUE OF SELL TO \"NONE\"\n",
    "    Sell = None\n",
    "    \n",
    "    if (len(p1) == 0 and len(p2) == 0) and (len(p1) != len(p2)):\n",
    "        Sell = False\n",
    "        SL_price = None\n",
    "        OB_size = None\n",
    "        Entry_price = None\n",
    "        SL_size = None\n",
    "        p2_bos = p4 = create_empty_time_price_df()\n",
    "        return Sell, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "        \n",
    "    try:\n",
    "        #FINDING P4 RANGE DATAFRAME\n",
    "        p4_range = p3_rates_frame\n",
    "        \n",
    "        #FIND THE INITIAL VALUE OF P4 ( MINIMUM LOW IN THE P4 RANGE)\n",
    "        p4y = p4_range[\"low\"].min()\n",
    "        mask = p4_range[\"low\"] == p4y\n",
    "        p4 = p4_range[mask].drop(['open','high','close'], axis=1).rename(columns={\"low\":\"price\"}).iloc[[-1]]\n",
    "        \n",
    "        # FINDING EVERY POSSIBLE P2 AFTER BOS (IF THERE IS A BOS)\n",
    "        p4y = p4[\"price\"].iloc[0]\n",
    "        p2_index = 0\n",
    "        p2_bos = create_empty_time_price_df()\n",
    "\n",
    "    except IndexError as IE:\n",
    "        Sell = False\n",
    "        SL_price = None\n",
    "        OB_size = None\n",
    "        Entry_price = None\n",
    "        SL_size = None\n",
    "        p2_bos = p4 = create_empty_time_price_df()\n",
    "        return Sell, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "        \n",
    "    while p2_index < len(p2):\n",
    "        if p2[\"price\"].iloc[p2_index] > p4y:\n",
    "            #GRAB THE INDIVIDUAL P2 THAT CAUSED BOS\n",
    "            p2_bos = pd.concat([p2_bos,p2.iloc[[p2_index]]], ignore_index=True)\n",
    "            p2_index += 1\n",
    "        else:\n",
    "            p2_index += 1\n",
    "            continue  \n",
    "            \n",
    "    \n",
    "    # DECIDING WHETHER TO SELL OR NOT\n",
    "    if len(p2_bos) == 0:\n",
    "        Sell = False\n",
    "        SL_price = None\n",
    "        OB_size = None\n",
    "        Entry_price = None\n",
    "        SL_size = None\n",
    "        return Sell, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "    else:\n",
    "        SL_price = round(p3[\"price\"].iloc[0] + 0.00007,5)\n",
    "        OB_size = round(p3[\"price\"].iloc[0] - p2_bos[\"price\"].min(), 5)\n",
    "        Entry_price = round(p2_bos[\"price\"].min() + 0.6*OB_size - 0.00007, 5)\n",
    "        SL_size = round(SL_price - Entry_price, 5)\n",
    "        TP1_price = round(Entry_price - (SL_size * 5), 5)\n",
    "        TP_size = Entry_price - sell_tp\n",
    "        RR = TP_size / SL_size\n",
    "\n",
    "        if RR >= 5:\n",
    "            Sell = True\n",
    "            return Sell, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "        else:\n",
    "            Sell = False\n",
    "            return Sell, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc01262f-fa27-4530-8ab2-59e6bde7b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_p4(p2_bos,p3,p4):\n",
    "    # OBTAINING THE PRICE AND TIME OF P2_BOS, P3 AND P4 and their difference\n",
    "    p4x = p4['time'].iloc[0]\n",
    "    p4y = p4['price'].iloc[0]\n",
    "    p3x = p3['time'].iloc[0]\n",
    "    p3y = p3['price'].iloc[0]\n",
    "    p2_bos_x = p2_bos['time'].iloc[0]\n",
    "    p2_bos_y = p2_bos['price'].iloc[0]\n",
    "    p4y_p3y = abs(p4y - p3y)\n",
    "    p3y_p2_bos_y = abs(p3y - p2_bos_y)\n",
    "    p3y_p4y = abs(p3y - p4y)\n",
    "    p2_bos_x_p3x = abs(p3x - p2_bos_x)\n",
    "    p3x_p4x = abs(p4x - p3x)\n",
    "    \n",
    "    # OBTAINING THE RATIOS TO VALIDATE P4\n",
    "    condition1 = pd.Timedelta(minutes=1) <= p4x - p3x <= pd.Timedelta(minutes=33)\n",
    "    condition2 = 0.167 <= (p3x_p4x/p2_bos_x_p3x) <= 4.5\n",
    "    condition3 = 1.0219 <= (p4y_p3y/p3y_p2_bos_y) <= 1.8889\n",
    "    condition = condition1 & condition2 & condition3\n",
    "\n",
    "    # OBTAIN THE DATAFRAME \n",
    "    \n",
    "    if condition:\n",
    "        p4_is_valid = True\n",
    "    elif condition == False:\n",
    "        p4_is_valid = False\n",
    "    \n",
    "    \n",
    "    return p4_is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26798027-38d4-4191-9127-a3b07ea7a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sell, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4 = validate_and_sell(rates_frame_p3, p3_rates_frame, sell_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b4e05c-5a98-4914-b98c-5a3ce335f2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ebc3d34-a104-460c-8631-d224d2788b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-17 04:47:00</td>\n",
       "      <td>2716.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    price\n",
       "0 2025-01-17 04:47:00  2716.98"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebef2f93-a6a9-4ff8-bacb-498e1a7f4c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-17 04:54:00</td>\n",
       "      <td>2714.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    price\n",
       "0 2025-01-17 04:54:00  2714.78"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee47601-f708-434b-a861-2132baf7455e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-17 04:54:00</td>\n",
       "      <td>2714.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    price\n",
       "0 2025-01-17 04:54:00  2714.78"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2_bos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04cd4a2b-36f5-42f2-88b7-d5adca2694d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-17 05:08:00</td>\n",
       "      <td>2717.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    price\n",
       "0 2025-01-17 05:08:00  2717.38"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73096c4-e115-4697-ac15-afe6b70f2efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>2025-01-17 05:25:00</td>\n",
       "      <td>2714.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   time    price\n",
       "744 2025-01-17 05:25:00  2714.54"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabcb93b-36e6-412b-a28c-40c67af96643",
   "metadata": {},
   "outputs": [],
   "source": [
    "SL_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c08076-a4f6-4a26-9845-5dd4f5915fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP1_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c8dd80-2720-4343-a342-445257597eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Entry_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ce59b-8d03-4af6-85da-0bd01d2e6576",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4_is_valid = verify_p4(p2_bos,p3,p4)\n",
    "print(p4_is_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49f7fd-aec0-47c5-ac73-6477466c2d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
