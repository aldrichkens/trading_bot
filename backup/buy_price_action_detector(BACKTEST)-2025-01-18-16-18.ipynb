{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0038cf8-4a0f-41d5-970b-3dae9b9a9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone, date\n",
    "from scipy.signal import find_peaks\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a03e725-05f7-4509-8d5d-0cab12474c65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Functions of the buy diagram ratio module\n",
    "\n",
    "def convert_maxima_to_LL_LH_df(Pay, p1_range_localmaximas):\n",
    "    Pa = p1_range_localmaximas[p1_range_localmaximas['high'] == Pay].drop(['open','low','close'], axis=1)\n",
    "    Pa = Pa.drop_duplicates(subset=['high'], keep='last')\n",
    "    Pa = Pa.rename(columns={\"high\":\"price\"})\n",
    "    return Pa\n",
    "    \n",
    "def convert_minima_to_LL_LH_df(Pay, condition, p1_range_localminimas):\n",
    "    Pa = p1_range_localminimas[(p1_range_localminimas['low'] == Pay) & condition].drop(['open','high','close'], axis=1)  \n",
    "    Pa = Pa.drop_duplicates(subset=['low'], keep='last')\n",
    "    Pa = Pa.rename(columns={\"low\":\"price\"})\n",
    "    return Pa\n",
    "\n",
    "def compute_index_Pa_x(Pay, p1_range_localmaximas):\n",
    "    try:\n",
    "        Pay_index = p1_range_localmaximas[p1_range_localmaximas['high'] == Pay].index[-1]\n",
    "    except IndexError as IE:\n",
    "        Pay_index = None\n",
    "    return Pay_index\n",
    "\n",
    "\n",
    "def create_tuples_p1_p3(df):\n",
    "    p1_p2_p3 = []\n",
    "    max_index = df.index.max()\n",
    "    no_of_comb = ((max_index + 1) // 2) -1  # +1 to include the last element for odd lengths\n",
    "    for i in range(no_of_comb):\n",
    "        p1_p2_p3.append((max_index, max_index - 2*(i+1) + 1, max_index - 2*(i+1)))\n",
    "    return p1_p2_p3\n",
    "\n",
    "def create_empty_p1_and_p2_and_p3_df():\n",
    "    p1 = pd.DataFrame(columns=['time','price'])\n",
    "    p1 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    p2 = pd.DataFrame(columns=['time','price'])\n",
    "    p2 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    p3 = pd.DataFrame(columns=['time','price'])\n",
    "    p3 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    return p1, p2, p3\n",
    "\n",
    "def create_empty_time_price_df():\n",
    "    df = pd.DataFrame(columns=['time','price'])\n",
    "    df = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    return df\n",
    "\n",
    "def create_empty_time_open_high_low_close_df():\n",
    "    df = pd.DataFrame(columns=['time','open','high','low','close'])\n",
    "    df = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'open': pd.Series(dtype='float'),\n",
    "                      'high': pd.Series(dtype='float'), 'low': pd.Series(dtype='float'),\n",
    "                      'close': pd.Series(dtype='float')})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91616590-77b4-4d69-bbf5-783be88f78bb",
   "metadata": {},
   "source": [
    "### START OF FAKE VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8543cca3-825c-408f-aaca-a78b959f5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fake Values only in here since this is backtest\n",
    "sell_tp = 0\n",
    "buy_tp = 1000\n",
    "#Importing the CSV file\n",
    "path = f\"./OHLC_data/EURJPY_20250114_20250116.csv\"\n",
    "OHLC_df = pd.read_csv(path)\n",
    "OHLC_df['time'] = pd.to_datetime(OHLC_df['time'], format='%Y-%m-%d %H:%M:%S')\n",
    "# DATA TO BE TESTED\n",
    "mask = (OHLC_df[\"time\"] >= \"2025-01-14 13:42:00\") & (OHLC_df[\"time\"] <= \"2025-01-14 15:42:00\")\n",
    "rates_frame = OHLC_df[mask]\n",
    "Last_110 = OHLC_df[mask].tail(110)\n",
    "MaxHighPrice = Last_110[\"high\"].max()\n",
    "MinLowPrice = Last_110[\"low\"].min()\n",
    "MaxHighPoint = Last_110[Last_110[\"high\"] == MaxHighPrice].iloc[[0]]\n",
    "MinLowPoint = Last_110[Last_110[\"low\"] == MinLowPrice].iloc[[0]]\n",
    "MaxHighTime = MaxHighPoint['time'].iloc[0]\n",
    "MinLowTime = MinLowPoint['time'].iloc[0]\n",
    "rates_frame_p3 = rates_frame[rates_frame[\"time\"]<= MinLowTime].tail(110)\n",
    "p3_rates_frame = rates_frame[rates_frame[\"time\"]>= MinLowTime]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be39226-e7a3-4758-b7d1-ed2186e78124",
   "metadata": {},
   "source": [
    "### END OF FAKE VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09e1369-93ea-4568-a4ca-50f1ea7ef988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO DETECT P1 P2 P3 for the EXTERNAL AND INTERNAL\n",
    "def obtain_p1_p2_p3(rates_frame_p3):\n",
    "    #obtaining the maximum point from the last 110 minutes for sells\n",
    "    Max_110_y = rates_frame_p3[\"high\"].max()\n",
    "    Max_110 = rates_frame_p3[rates_frame_p3[\"high\"] == Max_110_y].iloc[[-1]]\n",
    "    \n",
    "    #obtaining the minimum point from the last 110 minutes for sells\n",
    "    Min_110_y = rates_frame_p3[\"low\"].min()\n",
    "    Min_110 = rates_frame_p3[rates_frame_p3[\"low\"] == Min_110_y].iloc[[-1]]\n",
    "    \n",
    "    # Creating a new dataframe for the start and end of the minimum points in order to grab the data of local maxima and minima in an uptrend\n",
    "    p1_range_start_time = Max_110['time'].iloc[-1]\n",
    "    p1_range_end_time = Min_110[\"time\"].iloc[-1]\n",
    "    mask = rates_frame_p3[\"time\"].ge(p1_range_start_time) & rates_frame_p3[\"time\"].le(p1_range_end_time)\n",
    "    p1_range = rates_frame_p3[mask].reset_index(drop=True)\n",
    "    \n",
    "    # Find the index of local maximas\n",
    "    local_maximas_i,_ = find_peaks(p1_range['high'].values)\n",
    "    local_maximas_i = np.array(local_maximas_i)\n",
    "    \n",
    "    # Find the index of the local minima by inverting the data\n",
    "    local_minimas_i,_ = find_peaks(-p1_range['low'].values)\n",
    "    local_minimas_i = np.array(local_minimas_i)\n",
    "    \n",
    "    #Obtaining the dataframe of the local minimas and local maximas\n",
    "    p1_range_localminimas = p1_range[p1_range.index.isin(local_minimas_i)].reset_index(drop=True)\n",
    "    p1_range_localmaximas = p1_range[p1_range.index.isin(local_maximas_i)].reset_index(drop=True)\n",
    "    \n",
    "    # Finding the value of Pay1\n",
    "    Pay1 = Max_110_y\n",
    "    \n",
    "    #to find the y value of the possible 2nd local minima:\n",
    "    Pay3 = p1_range_localmaximas[\"high\"].max()\n",
    "    \n",
    "    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "    Pay3_index_range = Pay3_index\n",
    "    \n",
    "    while True:\n",
    "        #finding the index of the 1st local minima in the series \"p1_range_localminimas\" as P2\n",
    "        condition1 = p1_range_localminimas[\"time\"].ge(p1_range.iloc[0,0])\n",
    "        condition2 = p1_range_localminimas[\"time\"].le(p1_range_localmaximas.iloc[Pay3_index,0])\n",
    "        condition = condition1 & condition2\n",
    "        \n",
    "        Pay2 = p1_range_localminimas[condition == True]['low'].values\n",
    "    \n",
    "        try:\n",
    "            #finding the index of the 1st local minima in the series \"p1_range_localminimas\" as P2\n",
    "            condition1 = p1_range_localminimas[\"time\"].ge(p1_range.iloc[0,0])\n",
    "            condition2 = p1_range_localminimas[\"time\"].le(p1_range_localmaximas.iloc[Pay3_index,0])\n",
    "            condition = condition1 & condition2\n",
    "        \n",
    "            #to find the y value of the 1st local maxima:\n",
    "            Pay2 = p1_range_localminimas[condition == True]['low'].values\n",
    "            if len(Pay2) == 0:\n",
    "                #proceed with the next pay3 index and rerun the while loop\n",
    "                Pay3_index_range = Pay3_index_range + 1\n",
    "                Pay3 = p1_range_localmaximas.iloc[Pay3_index_range:,2].max()\n",
    "                Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "                continue\n",
    "            else:\n",
    "                #if value exists, find the minimum\n",
    "                Pay2 = min(Pay2)\n",
    "                break\n",
    "        except IndexError as err1:\n",
    "            break\n",
    "        except ValueError as ve:\n",
    "            continue\n",
    "        except TypeError as te:\n",
    "            break\n",
    "    \n",
    "            \n",
    "    #Making a new dataframe of the higher highs and higher lows approaching P3 in chronological order\n",
    "    LL_LH = create_empty_time_price_df()\n",
    "    \n",
    "    #Grabbing the data attached to Pay*\n",
    "    mask = rates_frame_p3['high'] == Pay1\n",
    "    pa1 = rates_frame_p3[mask].drop(['open','low','close'], axis=1).drop_duplicates(subset=['high'], keep='last').rename(columns={\"high\":\"price\"})\n",
    "    LL_LH_df = pd.concat([LL_LH, pa1], ignore_index=True)\n",
    "    \n",
    "    Pa2 = p1_range_localminimas[p1_range_localminimas['low'] == Pay2].drop(['open','high','close'], axis=1)\n",
    "    Pa2 = Pa2.drop_duplicates(subset=['low'], keep='last')\n",
    "    Pa2 = Pa2.rename(columns={\"low\":\"price\"})\n",
    "    LL_LH_df = pd.concat([LL_LH_df, Pa2], ignore_index=True)\n",
    "    LL_LH_df = pd.concat([LL_LH_df, convert_maxima_to_LL_LH_df(Pay3, p1_range_localmaximas)], ignore_index=True)\n",
    "    \n",
    "    #Resetting the values to avoid issues\n",
    "    Pay2 = Pay1_index = Pay3_index = 0\n",
    "    \n",
    "    #Assigning new values to find new sets of Pa2, Pa3\n",
    "    Pay1 = Pay3\n",
    "    Pay1_index = compute_index_Pa_x(Pay1, p1_range_localmaximas)\n",
    "    \n",
    "    #Resetting the values to avoid issues\n",
    "    Pay3 = Pay3_index = 0\n",
    "    \n",
    "    #Finding the initial value of Pay3\n",
    "    try:\n",
    "        Pay3 = p1_range_localmaximas.iloc[Pay1_index+1:,2].max()\n",
    "        Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "    except IndexError as err1:\n",
    "        print('There is no next p3. Continue with the external P1-P2-P3...')\n",
    "        Pay3 = None\n",
    "    \n",
    "    if Pay3 != None:\n",
    "        #Finding the values of the lower lows and lower highs and appending it to the LL_HH_df\n",
    "        while True:\n",
    "            Pay3_index_range = 0\n",
    "            try:\n",
    "                # Check if the current Pay3_index is beyond the end of p1_range_localminimas\n",
    "                if Pay3_index > len(p1_range_localmaximas):\n",
    "                    print(f\"End of p1_range_localmaximas reached.{Pay3_index}\")\n",
    "                    break\n",
    "                    \n",
    "                #finding the index of the next local maxima\n",
    "                condition1 = p1_range_localminimas[\"time\"].ge(p1_range_localmaximas.iloc[Pay1_index,0])\n",
    "                condition2 = p1_range_localminimas[\"time\"].le(p1_range_localmaximas.iloc[Pay3_index,0])\n",
    "                condition = condition1 & condition2\n",
    "        \n",
    "                \n",
    "                #to find the y value of the next local minima:\n",
    "                Pay2 = p1_range_localminimas[condition == True]['low'].values\n",
    "                \n",
    "                #previous ll index\n",
    "                pLL_index = LL_LH_df[LL_LH_df['price'] == Pay1].index[0] - 1\n",
    "                pLLy = LL_LH_df.iloc[pLL_index,1]\n",
    "        \n",
    "                #if Pay2 isnt existing for the current Pay3\n",
    "                condition3 = len(Pay2) == 0\n",
    "                \n",
    "                #if the current Pay2 is more than the previous ll\n",
    "                try:\n",
    "                    condition4 = p1_range_localminimas[condition == True]['low'].values.min() > pLLy\n",
    "                except ValueError as err2:\n",
    "                    Pay3_index = Pay3_index+1\n",
    "                    Pay3 = p1_range_localmaximas.iloc[Pay3_index:,2].max()\n",
    "                    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "                    continue\n",
    "                    \n",
    "                if condition3 or condition4:\n",
    "                    #proceed with the next pay3 index and rerun the while loop\n",
    "                    Pay2 = 0\n",
    "                    Pay3_index_range = Pay3_index+1\n",
    "                    Pay3 = p1_range_localmaximas.iloc[Pay3_index_range:,2].max()\n",
    "                    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "                    continue\n",
    "                else:\n",
    "                    Pay2=Pay2.min()\n",
    "                    #Appending to the LL_LH_df \n",
    "                    condition5 = (p1_range_localminimas['low'] == Pay2) & condition\n",
    "                    LL_LH_df = pd.concat([LL_LH_df, convert_minima_to_LL_LH_df(Pay2, condition5, p1_range_localminimas)], ignore_index=True)\n",
    "                    LL_LH_df = pd.concat([LL_LH_df, convert_maxima_to_LL_LH_df(Pay3, p1_range_localmaximas)], ignore_index=True)\n",
    "                    \n",
    "                    #Assigning new values to find new sets of Pa2, Pa3\n",
    "                    Pay1 = Pay3\n",
    "                    Pay1_index = compute_index_Pa_x(Pay1, p1_range_localmaximas)\n",
    "                    \n",
    "                    #Finding the initial value of Pay3\n",
    "                    Pay3 = p1_range_localmaximas.iloc[Pay1_index+1:,2].max()\n",
    "                    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "                    continue\n",
    "            except IndexError as err1:\n",
    "                break\n",
    "            except TypeError as te:\n",
    "                break\n",
    "    \n",
    "        #Append Max_110 to the dataframe:\n",
    "        Min_110 = Min_110.drop(['open','high','close'], axis=1).rename(columns={\"low\":\"price\"})\n",
    "        LL_LH_df = pd.concat([LL_LH_df, Min_110], ignore_index=True)\n",
    "        \n",
    "        # Create a tuple combining the list of possible p1-p2-p3 (initial values)\n",
    "        p1_p2_p3i = create_tuples_p1_p3(LL_LH_df)\n",
    "        \n",
    "        # finding the right p1-p2-p3 in terms of ratios\n",
    "        p1_p2_p3_index = []\n",
    "        for i in p1_p2_p3i:\n",
    "            p3i=i[0]\n",
    "            p2i=i[1]\n",
    "            p1i=i[2]\n",
    "            p3y_p2y = LL_LH_df.iloc[p3i,1] - LL_LH_df.iloc[p2i,1]\n",
    "            p2y_p1y = LL_LH_df.iloc[p2i,1] - LL_LH_df.iloc[p1i,1]\n",
    "            p3x_p2x = LL_LH_df.iloc[p3i,0] - LL_LH_df.iloc[p2i,0]\n",
    "            p2x_p1x = LL_LH_df.iloc[p2i,0] - LL_LH_df.iloc[p1i,0]\n",
    "        \n",
    "            # conditions for finding the right p1-p2-p3\n",
    "            condition1 = 1.027 <= abs(p3y_p2y/p2y_p1y) <= 1.9286\n",
    "            try:\n",
    "                condition2 = 0.217 <= abs(p3x_p2x/p2x_p1x) <= 5\n",
    "            except ZeroDivisionError as err1:\n",
    "                condition2 = False\n",
    "                \n",
    "            condition3 = p2x_p1x > pd.Timedelta(minutes=1)\n",
    "            condition4 = pd.Timedelta(minutes=2) <= p2x_p1x <= pd.Timedelta(minutes=24)\n",
    "            condition5 = pd.Timedelta(minutes=2) <= p3x_p2x <= pd.Timedelta(minutes=21)\n",
    "            condition = condition1 & condition2 & condition3 & condition4 & condition5\n",
    "            \n",
    "            if condition:\n",
    "                p1_p2_p3_index.append(i)\n",
    "    \n",
    "            p1, p2, p3 = create_empty_p1_and_p2_and_p3_df()\n",
    "        \n",
    "        if len(p1_p2_p3_index) == 0:\n",
    "            return p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3\n",
    "            \n",
    "        else:\n",
    "            for p3i, p2i, p1i in p1_p2_p3_index:\n",
    "                new_p3 = LL_LH_df.iloc[[p3i]]\n",
    "                new_p2 = LL_LH_df.iloc[[p2i]]\n",
    "                new_p1 = LL_LH_df.iloc[[p1i]]\n",
    "                p3 = pd.concat([p3,new_p3], ignore_index=True)\n",
    "                p2 = pd.concat([p2,new_p2], ignore_index=True)\n",
    "                p1 = pd.concat([p1,new_p1], ignore_index=True)\n",
    "                return  p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3\n",
    "        \n",
    "        if len(p1) != len(p2):\n",
    "            print(\"Index error! P1 and P2 doesn't match!\")\n",
    "            return p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3\n",
    "            \n",
    "    elif Pay3 == None:\n",
    "        p1, p2, p3 = create_empty_p1_and_p2_and_p3_df()\n",
    "        return p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c200fcaa-3fea-4a08-9b8b-a23cae107c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_buy(rates_frame_p3, p3_rates_frame, buy_tp):\n",
    "    TP1_price = None\n",
    "    # OBTAINING THE EXTERNAL p1-p2-p3\n",
    "    (\n",
    "        p1_range_localminimas,\n",
    "        p1_range_localmaximas,\n",
    "        LL_LH_df,\n",
    "        p1,\n",
    "        p2,\n",
    "        p3\n",
    "    ) = obtain_p1_p2_p3(rates_frame_p3)\n",
    "\n",
    "    \n",
    "    # FINDING THE VALUES OF THE OHLC DATAFRAME FROM THE EXTERNAL P2 AND P3 to HAVE THE INTERNAL P1-P2-P3\n",
    "    if not len(p1) == 0 and not len(p2) == 0:\n",
    "        p1_internal_range_start_time = p2[\"time\"].iloc[-1]\n",
    "        p1_internal_range_end_time = p3[\"time\"].iloc[-1]\n",
    "        \n",
    "        mask = (p1_internal_range_start_time <= rates_frame_p3[\"time\"]) & (rates_frame_p3[\"time\"] <= p1_internal_range_end_time)\n",
    "        p1_internal_range = rates_frame_p3[mask]\n",
    "    \n",
    "    try: \n",
    "        (\n",
    "            p1_range_localminimas_internal,\n",
    "            p1_range_localmaximas_internal,\n",
    "            LL_LH_df_internal, p1_internal,\n",
    "            p2_internal,\n",
    "            p3_internal\n",
    "        ) = obtain_p1_p2_p3(p1_internal_range)\n",
    "    except (TypeError, ValueError) as TE_VE:\n",
    "        p1_internal, p2_internal, p3_internal = create_empty_p1_and_p2_and_p3_df()\n",
    "        p1_range_localminimas_internal = p1_range_localmaximas_internal = create_empty_time_open_high_low_close_df()\n",
    "        LL_LH_internal = create_empty_time_price_df()\n",
    "    except UnboundLocalError as ULE:\n",
    "        #if there is no p1-p2-p3 because of the time limits, it will return a ULE, therefore, find the p1-p2-p3 with another dataframe\n",
    "        #tail 42 is just temporary, gather more data for this\n",
    "        p1_internal_range = rates_frame_p3.tail(42)\n",
    "    \n",
    "        try:\n",
    "            (\n",
    "                p1_range_localminimas_internal,\n",
    "                p1_range_localmaximas_internal,\n",
    "                LL_LH_df_internal, p1_internal,\n",
    "                p2_internal,\n",
    "                p3_internal\n",
    "            ) = obtain_p1_p2_p3(p1_internal_range)\n",
    "        except (TypeError, UnboundLocalError) as TE_ULE:\n",
    "            p1_internal, p2_internal, p3_internal = create_empty_p1_and_p2_and_p3_df()\n",
    "            p1_range_localminimas_internal = p1_range_localmaximas_internal = create_empty_time_open_high_low_close_df()\n",
    "            LL_LH_df_internal = create_empty_time_price_df()\n",
    "\t\t\t\n",
    "    \n",
    "    # APPEND THE VALUES OF THE INTERNAL P1, P2, P3 to the external one. \n",
    "    p1 = pd.concat([p1,p1_internal], ignore_index=True)\n",
    "    p2 = pd.concat([p2,p2_internal], ignore_index=True)\n",
    "    p3 = pd.concat([p3,p3_internal], ignore_index=True)\n",
    "    \n",
    "    #SETTING THE INITIAL VALUE OF BUY TO \"NONE\"\n",
    "    Buy = None\n",
    "    \n",
    "    if (len(p1) == 0 and len(p2) == 0) and (len(p1) != len(p2)):\n",
    "        Buy = False\n",
    "        SL_price = None\n",
    "        OB_size = None\n",
    "        Entry_price = None\n",
    "        SL_size = None\n",
    "        p2_bos = p4 = create_empty_time_price_df()\n",
    "        return Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "        \n",
    "    try:\n",
    "\t\t#FINDING P4 RANGE DATAFRAME\n",
    "        p4_range = p3_rates_frame\n",
    "        \n",
    "        #FIND THE INITIAL VALUE OF P4 ( MINIMUM LOW IN THE P4 RANGE)\n",
    "        p4y = p4_range[\"high\"].max()\n",
    "        mask = p4_range[\"high\"] == p4y\n",
    "        p4 = p4_range[mask].drop(['open','low','close'], axis=1).rename(columns={\"high\":\"price\"}).iloc[[-1]]\n",
    "        \n",
    "        # FINDING EVERY POSSIBLE P2 AFTER BOS (IF THERE IS A BOS)\n",
    "        p4y = p4[\"price\"].iloc[0]\n",
    "        p2_index = 0\n",
    "        p2_bos = create_empty_time_price_df()\n",
    "\n",
    "    except IndexError as IE:\n",
    "        Buy = False\n",
    "        SL_price = None\n",
    "        OB_size = None\n",
    "        Entry_price = None\n",
    "        SL_size = None\n",
    "        p2_bos = p4 = create_empty_time_price_df()\n",
    "        return Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "\t\t\n",
    "    while p2_index < len(p2):\n",
    "        if p2[\"price\"].iloc[p2_index] < p4y:\n",
    "            #GRAB THE INDIVIDUAL P2 THAT CAUSED BOS\n",
    "            p2_bos = pd.concat([p2_bos,p2.iloc[[p2_index]]], ignore_index=True)\n",
    "            p2_index += 1\n",
    "        else:\n",
    "            p2_index += 1\n",
    "            continue  \n",
    "            \n",
    "    \n",
    "    # DECIDING WHETHER TO BUY OR NOT\n",
    "    if len(p2_bos) == 0:\n",
    "        Buy = False\n",
    "        SL_price = None\n",
    "        OB_size = None\n",
    "        Entry_price = None\n",
    "        SL_size = None\n",
    "        return Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "    else:\n",
    "        SL_price = p3[\"price\"].iloc[0] - 0.00007\n",
    "        OB_size = round(p2_bos[\"price\"].max() - p3[\"price\"].iloc[0], 5)\n",
    "        Entry_price = round(p2_bos[\"price\"].max() - 0.6*OB_size + 0.00007, 5)\n",
    "        SL_size = round(Entry_price - SL_price, 5)\n",
    "        TP1_price = round(Entry_price + (SL_size * 5), 5)\n",
    "        TP_size = buy_tp - Entry_price\n",
    "        RR = TP_size / SL_size\n",
    "    \n",
    "        if RR >= 5:\n",
    "            Buy = True\n",
    "            return Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "        else:\n",
    "            Buy = False\n",
    "            return Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d949b2d8-77d7-4c47-8aa4-53e3a6bd4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_p4(p2_bos,p3,p4):\n",
    "    # OBTAINING THE PRICE AND TIME OF P2_BOS, P3 AND P4 and their difference\n",
    "    p4x = p4['time'].iloc[0]\n",
    "    p4y = p4['price'].iloc[0]\n",
    "    p3x = p3['time'].iloc[0]\n",
    "    p3y = p3['price'].iloc[0]\n",
    "    p2_bos_x = p2_bos['time'].iloc[0]\n",
    "    p2_bos_y = p2_bos['price'].iloc[0]\n",
    "    p4y_p3y = abs(p4y - p3y)\n",
    "    p3y_p2_bos_y = abs(p3y - p2_bos_y)\n",
    "    p3y_p4y = abs(p3y - p4y)\n",
    "    p2_bos_x_p3x = abs(p3x - p2_bos_x)\n",
    "    p3x_p4x = abs(p4x - p3x)\n",
    "    \n",
    "    # OBTAINING THE RATIOS TO VALIDATE P4\n",
    "    condition1 = pd.Timedelta(minutes=1) <= p4x - p3x <= pd.Timedelta(minutes=33)\n",
    "    condition2 = 0.167 <= (p3x_p4x/p2_bos_x_p3x) <= 4.5\n",
    "    condition3 = 1.0219 <= (p4y_p3y/p3y_p2_bos_y) <= 1.8889\n",
    "    condition = condition1 & condition2 & condition3\n",
    "\n",
    "    if condition:\n",
    "        p4_is_valid = True\n",
    "    elif condition == False:\n",
    "        p4_is_valid = False\n",
    "\n",
    "    return p4_is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8183dfb6-7907-4c03-b75d-09f063b9eff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4 = validate_and_buy(rates_frame_p3, p3_rates_frame, buy_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4496e722-20a2-4ca5-b3b4-da7804f41901",
   "metadata": {},
   "outputs": [],
   "source": [
    "Buy, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a75638-80a0-4d0d-bc7d-3a79ec7a91c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017b462-1784-4961-8980-8b7dafbb790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4159faf-2928-4deb-a731-56ee432aa304",
   "metadata": {},
   "outputs": [],
   "source": [
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e6512e-8738-4ac1-a823-31ce8f1d6ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d6325-982e-491e-ab41-9e4e4ebd5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3 = obtain_p1_p2_p3(rates_frame_p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03ff2a-77ac-4003-8898-1a02bcbf8856",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4976042-e787-4b8c-96f7-5a3cd089144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9cd53-97b3-413e-8e20-9695b583c9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "910bdc7a-7c37-4cc2-aa36-616810c481db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p4_is_valid = verify_p4(p2_bos,p3,p4)\n",
    "p4_is_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89095b80-1378-4c16-9183-66f8b530212f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
