{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0038cf8-4a0f-41d5-970b-3dae9b9a9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone, date\n",
    "from scipy.signal import find_peaks\n",
    "import pytz\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a03e725-05f7-4509-8d5d-0cab12474c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions of the sell diagram ratio module\n",
    "\n",
    "def convert_minima_to_HH_HL_df(Pay):\n",
    "    Pa = p1_range_localminimas[p1_range_localminimas['low'] == Pay].drop(['open','high','close'], axis=1)\n",
    "    Pa = Pa.drop_duplicates(subset=['low'], keep='last')\n",
    "    Pa = Pa.rename(columns={\"low\":\"price\"})\n",
    "    return Pa\n",
    "\n",
    "def convert_maxima_to_HH_HL_df(Pay, condition):\n",
    "    Pa = p1_range_localmaximas[(p1_range_localmaximas['high'] == Pay) & condition].drop(['open','low','close'], axis=1)  \n",
    "    Pa = Pa.drop_duplicates(subset=['high'], keep='last')\n",
    "    Pa = Pa.rename(columns={\"high\":\"price\"})\n",
    "    return Pa\n",
    "    \n",
    "def compute_index_Pa_n(Pay):\n",
    "    Pay_index = p1_range_localminimas[p1_range_localminimas['low'] == Pay].index[-1]\n",
    "    return Pay_index\n",
    "\n",
    "def create_tuples_p1_p3(df):\n",
    "    p1_p2_p3 = []\n",
    "    max_index = df.index.max()\n",
    "    no_of_comb = ((max_index + 1) // 2) -1  # +1 to include the last element for odd lengths\n",
    "    for i in range(no_of_comb):\n",
    "        p1_p2_p3.append((max_index, max_index - 2*(i+1) + 1, max_index - 2*(i+1)))\n",
    "    return p1_p2_p3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545ca29f-1f5f-4370-85a6-5e77e17531a8",
   "metadata": {},
   "source": [
    "### start to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "820ca5fd-a383-48d0-a346-d88b8ba55ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   time     open     high      low    close\n",
      "850 2025-01-06 14:10:00  1.04169  1.04182  1.04135  1.04143\n",
      "851 2025-01-06 14:11:00  1.04143  1.04144  1.04104  1.04107\n",
      "852 2025-01-06 14:12:00  1.04106  1.04132  1.04103  1.04129\n",
      "853 2025-01-06 14:13:00  1.04130  1.04147  1.04123  1.04129\n",
      "854 2025-01-06 14:14:00  1.04129  1.04142  1.04102  1.04106\n",
      "..                  ...      ...      ...      ...      ...\n",
      "955 2025-01-06 15:55:00  1.04144  1.04153  1.04123  1.04150\n",
      "956 2025-01-06 15:56:00  1.04149  1.04151  1.04120  1.04143\n",
      "957 2025-01-06 15:57:00  1.04142  1.04182  1.04130  1.04158\n",
      "958 2025-01-06 15:58:00  1.04155  1.04160  1.04133  1.04143\n",
      "959 2025-01-06 15:59:00  1.04144  1.04171  1.04144  1.04168\n",
      "\n",
      "[110 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Fake Values only in here since this is backtest\n",
    "\n",
    "#Importing the CSV file\n",
    "path = f\"./OHLC_data/EURUSD_20250106_20250107.csv\"\n",
    "\n",
    "OHLC_df = pd.read_csv(path)\n",
    "OHLC_df['time'] = pd.to_datetime(OHLC_df['time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "mask = (13 < OHLC_df[\"time\"].dt.hour) &  (OHLC_df[\"time\"].dt.hour < 16)\n",
    "Last_110 = OHLC_df[mask].tail(110)\n",
    "print(Last_110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b96e68-1663-44ed-92f2-a67bad6b2898",
   "metadata": {},
   "source": [
    "### end to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9131b692-0c4d-4dcc-9506-9f93c2a21488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def obtain_p1_p2_p3(Last_110):\n",
    "    global p1_range_localminimas, p1_range_localmaximas, HH_HL_df, p1, p2, p3\n",
    "    \n",
    "    #obtaining the maximum point from the last 110 minutes for sells\n",
    "    Max_110_y = Last_110[\"high\"].max()\n",
    "    Max_110 = Last_110[Last_110[\"high\"] == Max_110_y].iloc[[-1]]\n",
    "    \n",
    "    #obtaining the minimum point from the last 110 minutes for sells\n",
    "    Min_110_y = Last_110[\"low\"].min()\n",
    "    Min_110 = Last_110[Last_110[\"low\"] == Min_110_y].iloc[[-1]]\n",
    "    \n",
    "    # Creating a new dataframe for the start and end of the minimum points in order to grab the data of local maxima and minima in an uptrend\n",
    "    p1_range_start_time = Min_110[\"time\"].iloc[-1]\n",
    "    p1_range_end_time = Max_110['time'].iloc[-1]\n",
    "    mask = Last_110[\"time\"].ge(p1_range_start_time) & Last_110[\"time\"].le(p1_range_end_time)\n",
    "    p1_range = Last_110[mask].reset_index(drop=True)\n",
    "    \n",
    "    # Find the index of local maximas\n",
    "    local_maximas_i,_ = find_peaks(p1_range['high'].values)\n",
    "    local_maximas_i = np.array(local_maximas_i)\n",
    "    \n",
    "    # Find the index of the local minima by inverting the data\n",
    "    local_minimas_i,_ = find_peaks(-p1_range['low'].values)\n",
    "    local_minimas_i = np.array(local_minimas_i)\n",
    "    \n",
    "    #Obtaining the dataframe of the local minimas and local maximas\n",
    "    p1_range_localminimas = p1_range[p1_range.index.isin(local_minimas_i)].reset_index(drop=True)\n",
    "    p1_range_localmaximas = p1_range[p1_range.index.isin(local_maximas_i)].reset_index(drop=True)\n",
    "    \n",
    "    # Finding the value of Pay1\n",
    "    Pay1 = p1_range_localminimas[\"low\"].min()\n",
    "    \n",
    "    #Finding the index of the first local minima in the series \"p1_range_localminimas\"\n",
    "    Pay1_index = p1_range_localminimas[p1_range_localminimas['low'] == Pay1].index.min()\n",
    "    \n",
    "    \n",
    "    #Dropping the minimas before the first local minimas in the series \"p1_range_localminimas\"\n",
    "    mask = p1_range_localminimas.index >= Pay1_index\n",
    "    p1_range_localminimas = p1_range_localminimas[mask].reset_index(drop=True)\n",
    "    p1_range_localminimas\n",
    "    #Finding the index of the first local minima\n",
    "    Pay1_index = compute_index_Pa_n(Pay1)\n",
    "    \n",
    "    #to find the y value of the possible 2nd local minima:\n",
    "    Pay3 = p1_range_localminimas.iloc[Pay1_index+1:,3].min()\n",
    "    Pay3_index = compute_index_Pa_n(Pay3)\n",
    "    Pay3_index_range = Pay3_index\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            #finding the index of the 1st local maxima in the series \"p1_range_localminimas\"\n",
    "            condition1 = p1_range_localmaximas[\"time\"].ge(p1_range_localminimas.iloc[Pay1_index,0])\n",
    "            condition2 = p1_range_localmaximas[\"time\"].le(p1_range_localminimas.iloc[Pay3_index,0])\n",
    "            condition = condition1 & condition2\n",
    "            #Test value\n",
    "            #condition = pd.Series([False] * 7)\n",
    "            \n",
    "            #to find the y value of the 1st local maxima:\n",
    "            Pay2 = p1_range_localmaximas[condition == True]['high'].values\n",
    "            if len(Pay2) == 0:\n",
    "                #proceed with the next pay3 index and rerun the while loop\n",
    "                Pay3_index_range = Pay3_index_range + 1\n",
    "                Pay3 = p1_range_localminimas.iloc[Pay3_index_range:,3].min()\n",
    "                Pay3_index = compute_index_Pa_n(Pay3)\n",
    "                continue\n",
    "            else:\n",
    "                Pay2=Pay2.max()\n",
    "                break\n",
    "        except IndexError as err1:\n",
    "            break\n",
    "            \n",
    "    #Making a new dataframe of the higher highs and higher lows approaching P3 in chronological order\n",
    "    HH_HL_df = pd.DataFrame(columns=['time','price'])\n",
    "    HH_HL_df = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    \n",
    "    #Grabbing the data attached to Pay*\n",
    "    HH_HL_df = pd.concat([HH_HL_df, convert_minima_to_HH_HL_df(Pay1)], ignore_index=True)\n",
    "    \n",
    "    Pa2 = p1_range_localmaximas[p1_range_localmaximas['high'] == Pay2].drop(['open','low','close'], axis=1)\n",
    "    Pa2 = Pa2.drop_duplicates(subset=['high'], keep='last')\n",
    "    Pa2 = Pa2.rename(columns={\"high\":\"price\"})\n",
    "    HH_HL_df = pd.concat([HH_HL_df, Pa2], ignore_index=True)\n",
    "    HH_HL_df = pd.concat([HH_HL_df, convert_minima_to_HH_HL_df(Pay3)], ignore_index=True)\n",
    "    \n",
    "    #Resetting the values to avoid issues\n",
    "    Pay2 = Pay1_index = Pay3_index = 0\n",
    "    \n",
    "    #Assigning new values to find new sets of Pa2, Pa3\n",
    "    Pay1 = Pay3\n",
    "    Pay1_index = compute_index_Pa_n(Pay1)\n",
    "    \n",
    "    #Resetting the values to avoid issues\n",
    "    Pay3 = Pay3_index = 0\n",
    "    \n",
    "    #Finding the initial value of Pay3\n",
    "    Pay3 = p1_range_localminimas.iloc[Pay1_index+1:,3].min()\n",
    "    Pay3_index = compute_index_Pa_n(Pay3)\n",
    "    \n",
    "    \n",
    "    #Finding the values of the higher lows and higher highs and appending it to the HH_HL_df\n",
    "    while True:\n",
    "        Pay3_index_range = 0\n",
    "        try:\n",
    "            # Check if the current Pay3_index is beyond the end of p1_range_localminimas\n",
    "            if Pay3_index > len(p1_range_localminimas):\n",
    "                print(f\"End of p1_range_localminimas reached.{Pay3_index}\")\n",
    "                break\n",
    "                \n",
    "            #finding the index of the next local maxima\n",
    "            condition1 = p1_range_localmaximas[\"time\"].ge(p1_range_localminimas.iloc[Pay1_index,0])\n",
    "            condition2 = p1_range_localmaximas[\"time\"].le(p1_range_localminimas.iloc[Pay3_index,0])\n",
    "            condition = condition1 & condition2\n",
    "    \n",
    "            \n",
    "            #to find the y value of the next local maxima:\n",
    "            Pay2 = p1_range_localmaximas[condition == True]['high'].values\n",
    "            \n",
    "            #previous HH index\n",
    "            pHH_index = HH_HL_df[HH_HL_df['price'] == Pay1].index[0] - 1\n",
    "            pHHy = HH_HL_df.iloc[pHH_index,1]\n",
    "    \n",
    "            #if Pay2 isnt existing for the current Pay3\n",
    "            condition3 = len(Pay2) == 0\n",
    "            \n",
    "            #if the current Pay2 is less than the previous HH\n",
    "            try:\n",
    "                condition4 = p1_range_localmaximas[condition == True]['high'].values.max() < pHHy\n",
    "            except ValueError as err2:\n",
    "                Pay3_index = Pay3_index+1\n",
    "                Pay3 = p1_range_localminimas.iloc[Pay3_index:,3].min()\n",
    "                Pay3_index = compute_index_Pa_n(Pay3)\n",
    "                continue\n",
    "            if condition3 or condition4:\n",
    "                #proceed with the next pay3 index and rerun the while loop\n",
    "                Pay2 = 0\n",
    "                Pay3_index_range = Pay3_index+1\n",
    "                Pay3 = p1_range_localminimas.iloc[Pay3_index_range:,3].min()\n",
    "                Pay3_index = compute_index_Pa_n(Pay3)\n",
    "                continue\n",
    "            else:\n",
    "                Pay2=Pay2.max()\n",
    "                #Appending to the HH_HL_df \n",
    "                condition5 = (p1_range_localmaximas['high'] == Pay2) & condition\n",
    "                HH_HL_df = pd.concat([HH_HL_df, convert_maxima_to_HH_HL_df(Pay2, condition5)], ignore_index=True)\n",
    "                HH_HL_df = pd.concat([HH_HL_df, convert_minima_to_HH_HL_df(Pay3)], ignore_index=True)\n",
    "                \n",
    "                #Assigning new values to find new sets of Pa2, Pa3\n",
    "                Pay1 = Pay3\n",
    "                Pay1_index = compute_index_Pa_n(Pay1)\n",
    "                \n",
    "                #Finding the initial value of Pay3\n",
    "                Pay3 = p1_range_localminimas.iloc[Pay1_index+1:,3].min()\n",
    "                Pay3_index = compute_index_Pa_n(Pay3)\n",
    "                continue\n",
    "        except IndexError as err1:\n",
    "            break\n",
    "    \n",
    "    \n",
    "    #Append Max_110 to the dataframe:\n",
    "    Max_110 = Max_110.drop(['open','low','close'], axis=1)\n",
    "    Max_110 = Max_110.rename(columns={\"high\":\"price\"})\n",
    "    HH_HL_df = pd.concat([HH_HL_df, Max_110], ignore_index=True)\n",
    "    \n",
    "    # Create a tuple combining the list of possible p1-p2-p3 (initial values)\n",
    "    p1_p2_p3i = create_tuples_p1_p3(HH_HL_df)\n",
    "    \n",
    "    # finding the right p1-p2-p3 in terms of ratios\n",
    "    p1_p2_p3_index = []\n",
    "    for i in p1_p2_p3i:\n",
    "        p3i=i[0]\n",
    "        p2i=i[1]\n",
    "        p1i=i[2]\n",
    "        p3y_p2y = HH_HL_df.iloc[p3i,1] - HH_HL_df.iloc[p2i,1]\n",
    "        p2y_p1y = HH_HL_df.iloc[p2i,1] - HH_HL_df.iloc[p1i,1]\n",
    "        p3x_p2x = HH_HL_df.iloc[p3i,0] - HH_HL_df.iloc[p2i,0]\n",
    "        p2x_p1x = HH_HL_df.iloc[p2i,0] - HH_HL_df.iloc[p1i,0]\n",
    "    \n",
    "        # conditions for finding the right p1-p2-p3\n",
    "        condition1 = 1.027 < abs(p3y_p2y/p2y_p1y) < 1.9286\n",
    "        try:\n",
    "            condition2 = 0.333 < p3x_p2x/p2x_p1x < 5\n",
    "        except ZeroDivisionError as err1:\n",
    "            condition2 = False\n",
    "        condition3 = p2x_p1x > pd.Timedelta(minutes=1)\n",
    "        condition4 = pd.Timedelta(minutes=2) <= p2x_p1x <= pd.Timedelta(minutes=24)\n",
    "        condition5 = pd.Timedelta(minutes=2) <= p3x_p2x <= pd.Timedelta(minutes=21)\n",
    "        condition = condition1 & condition2 & condition3 & condition4 & condition5\n",
    "        \n",
    "        if condition:\n",
    "            p1_p2_p3_index.append(i)\n",
    "    \n",
    "    p1 = pd.DataFrame(columns=['time','price'])\n",
    "    p1 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    p2 = pd.DataFrame(columns=['time','price'])\n",
    "    p2 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    p3 = pd.DataFrame(columns=['time','price'])\n",
    "    p3 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    \n",
    "    if len(p1_p2_p3_index) == 0:\n",
    "        print(\"There are no P1-P2-P3 yet. Let's keep waiting...\")\n",
    "        return\n",
    "    else:\n",
    "        for p3i, p2i, p1i in p1_p2_p3_index:\n",
    "            new_p3 = HH_HL_df.iloc[[p3i]]\n",
    "            new_p2 = HH_HL_df.iloc[[p2i]]\n",
    "            new_p1 = HH_HL_df.iloc[[p1i]]\n",
    "            p3 = pd.concat([p3,new_p3], ignore_index=True)\n",
    "            p2 = pd.concat([p2,new_p2], ignore_index=True)\n",
    "            p1 = pd.concat([p1,new_p1], ignore_index=True)\n",
    "            return\n",
    "    \n",
    "    if len(p1) != len(p2):\n",
    "        print(\"Index error! P1 and P2 doesn't match!\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07982c2b-ceb8-4d06-881a-933a9b79fc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-06 14:53:00</td>\n",
       "      <td>1.03963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-06 15:02:00</td>\n",
       "      <td>1.04203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-06 15:04:00</td>\n",
       "      <td>1.04158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-06 15:10:00</td>\n",
       "      <td>1.04257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-06 15:13:00</td>\n",
       "      <td>1.04192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-01-06 15:17:00</td>\n",
       "      <td>1.04274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-01-06 15:18:00</td>\n",
       "      <td>1.04201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-01-06 15:21:00</td>\n",
       "      <td>1.04296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-01-06 15:22:00</td>\n",
       "      <td>1.04245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-01-06 15:29:00</td>\n",
       "      <td>1.04365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    price\n",
       "0 2025-01-06 14:53:00  1.03963\n",
       "1 2025-01-06 15:02:00  1.04203\n",
       "2 2025-01-06 15:04:00  1.04158\n",
       "3 2025-01-06 15:10:00  1.04257\n",
       "4 2025-01-06 15:13:00  1.04192\n",
       "5 2025-01-06 15:17:00  1.04274\n",
       "6 2025-01-06 15:18:00  1.04201\n",
       "7 2025-01-06 15:21:00  1.04296\n",
       "8 2025-01-06 15:22:00  1.04245\n",
       "9 2025-01-06 15:29:00  1.04365"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HH_HL_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6815204-3316-4273-b114-bea93c2ee200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, price]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15e27e40-5ff2-491f-915b-52df74948ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, price]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72e7f437-2a87-4b52-be7b-b681cb039ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, price]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cd9e66f-2364-4cf4-ab8b-e4ecfa5a0776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no P1-P2-P3 yet. Let's keep waiting...\n"
     ]
    }
   ],
   "source": [
    "obtain_p1_p2_p3(Last_110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b1ca7-8c8f-40ed-b661-9c51f8444ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b2175-0211-4fdc-885d-2b3de2e6f2aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
