{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0038cf8-4a0f-41d5-970b-3dae9b9a9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone, date\n",
    "from scipy.signal import find_peaks\n",
    "import pytz\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a03e725-05f7-4509-8d5d-0cab12474c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions of the buy diagram ratio module\n",
    "\n",
    "def convert_maxima_to_LL_LH_df(Pay, p1_range_localmaximas):\n",
    "    Pa = p1_range_localmaximas[p1_range_localmaximas['high'] == Pay].drop(['open','low','close'], axis=1)\n",
    "    Pa = Pa.drop_duplicates(subset=['high'], keep='last')\n",
    "    Pa = Pa.rename(columns={\"high\":\"price\"})\n",
    "    return Pa\n",
    "    \n",
    "def convert_minima_to_LL_LH_df(Pay, condition, p1_range_localminimas):\n",
    "    Pa = p1_range_localminimas[(p1_range_localminimas['low'] == Pay) & condition].drop(['open','high','close'], axis=1)  \n",
    "    Pa = Pa.drop_duplicates(subset=['low'], keep='last')\n",
    "    Pa = Pa.rename(columns={\"low\":\"price\"})\n",
    "    return Pa\n",
    "\n",
    "def compute_index_Pa_x(Pay, p1_range_localmaximas):\n",
    "    try:\n",
    "        Pay_index = p1_range_localmaximas[p1_range_localmaximas['high'] == Pay].index[-1]\n",
    "    except IndexError as IE:\n",
    "        Pay_index = None\n",
    "    return Pay_index\n",
    "\n",
    "\n",
    "def create_tuples_p1_p3(df):\n",
    "    p1_p2_p3 = []\n",
    "    max_index = df.index.max()\n",
    "    no_of_comb = ((max_index + 1) // 2) -1  # +1 to include the last element for odd lengths\n",
    "    for i in range(no_of_comb):\n",
    "        p1_p2_p3.append((max_index, max_index - 2*(i+1) + 1, max_index - 2*(i+1)))\n",
    "    return p1_p2_p3\n",
    "\n",
    "def create_empty_p1_and_p2_and_p3_df():\n",
    "    p1 = pd.DataFrame(columns=['time','price'])\n",
    "    p1 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    p2 = pd.DataFrame(columns=['time','price'])\n",
    "    p2 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    p3 = pd.DataFrame(columns=['time','price'])\n",
    "    p3 = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    return p1, p2, p3\n",
    "\n",
    "def create_empty_time_price_df():\n",
    "    df = pd.DataFrame(columns=['time','price'])\n",
    "    df = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    return df\n",
    "\n",
    "def create_empty_time_open_high_low_close_df():\n",
    "    df = pd.DataFrame(columns=['time','open','high','low','close'])\n",
    "    df = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'open': pd.Series(dtype='float'),\n",
    "                      'high': pd.Series(dtype='float'), 'low': pd.Series(dtype='float'),\n",
    "                      'close': pd.Series(dtype='float')})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545ca29f-1f5f-4370-85a6-5e77e17531a8",
   "metadata": {},
   "source": [
    "### start \"to delete\" fictitious values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d788b2-8979-4f0f-9806-d53f892208fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fake Values only in here since this is backtest\n",
    "\n",
    "#Importing the CSV file\n",
    "path = f\"./OHLC_data/EURJPY_20250114_20250116.csv\"\n",
    "\n",
    "OHLC_df = pd.read_csv(path)\n",
    "OHLC_df['time'] = pd.to_datetime(OHLC_df['time'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf67dd24-9baa-4597-8f39-5e1620867ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    time     open     high      low    close\n",
      "1315 2025-01-14 13:55:00  161.917  161.930  161.901  161.925\n",
      "1316 2025-01-14 13:56:00  161.922  161.957  161.922  161.957\n",
      "1317 2025-01-14 13:57:00  161.960  161.964  161.947  161.950\n",
      "1318 2025-01-14 13:58:00  161.949  161.977  161.943  161.977\n",
      "1319 2025-01-14 13:59:00  161.976  161.980  161.946  161.946\n",
      "...                  ...      ...      ...      ...      ...\n",
      "1420 2025-01-14 15:40:00  161.771  161.775  161.713  161.720\n",
      "1421 2025-01-14 15:41:00  161.720  161.721  161.662  161.701\n",
      "1422 2025-01-14 15:42:00  161.704  161.709  161.643  161.665\n",
      "1423 2025-01-14 15:43:00  161.665  161.724  161.663  161.710\n",
      "1424 2025-01-14 15:44:00  161.711  161.718  161.679  161.713\n",
      "\n",
      "[110 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# DATA TO BE TESTED\n",
    "mask = (OHLC_df[\"time\"] >= \"2025-01-14 11:48:00\") & (OHLC_df[\"time\"] <= \"2025-01-14 15:44:00\")\n",
    "Last_110 = OHLC_df[mask].tail(110)\n",
    "print(Last_110)\n",
    "sell_tp = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b96e68-1663-44ed-92f2-a67bad6b2898",
   "metadata": {},
   "source": [
    "### end \"to delete\" fictitious values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a09e1369-93ea-4568-a4ca-50f1ea7ef988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION TO DETECT P1 P2 P3 for the EXTERNAL AND INTERNAL\n",
    "def obtain_p1_p2_p3(Last_110):\n",
    "    #obtaining the maximum point from the last 110 minutes for sells\n",
    "    Max_110_y = Last_110[\"high\"].max()\n",
    "    Max_110 = Last_110[Last_110[\"high\"] == Max_110_y].iloc[[-1]]\n",
    "    \n",
    "    #obtaining the minimum point from the last 110 minutes for sells\n",
    "    Min_110_y = Last_110[\"low\"].min()\n",
    "    Min_110 = Last_110[Last_110[\"low\"] == Min_110_y].iloc[[-1]]\n",
    "    \n",
    "    # Creating a new dataframe for the start and end of the minimum points in order to grab the data of local maxima and minima in an uptrend\n",
    "    p1_range_start_time = Max_110['time'].iloc[-1]\n",
    "    p1_range_end_time = Min_110[\"time\"].iloc[-1]\n",
    "    mask = Last_110[\"time\"].ge(p1_range_start_time) & Last_110[\"time\"].le(p1_range_end_time)\n",
    "    p1_range = Last_110[mask].reset_index(drop=True)\n",
    "    \n",
    "    # Find the index of local maximas\n",
    "    local_maximas_i,_ = find_peaks(p1_range['high'].values)\n",
    "    local_maximas_i = np.array(local_maximas_i)\n",
    "    \n",
    "    # Find the index of the local minima by inverting the data\n",
    "    local_minimas_i,_ = find_peaks(-p1_range['low'].values)\n",
    "    local_minimas_i = np.array(local_minimas_i)\n",
    "    \n",
    "    #Obtaining the dataframe of the local minimas and local maximas\n",
    "    p1_range_localminimas = p1_range[p1_range.index.isin(local_minimas_i)].reset_index(drop=True)\n",
    "    p1_range_localmaximas = p1_range[p1_range.index.isin(local_maximas_i)].reset_index(drop=True)\n",
    "    \n",
    "    # Finding the value of Pay1\n",
    "    Pay1 = Max_110_y\n",
    "    \n",
    "    #to find the y value of the possible 2nd local minima:\n",
    "    Pay3 = p1_range_localmaximas[\"high\"].max()\n",
    "    \n",
    "    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "    Pay3_index_range = Pay3_index\n",
    "    \n",
    "    while True:\n",
    "        #finding the index of the 1st local minima in the series \"p1_range_localminimas\" as P2\n",
    "        condition1 = p1_range_localminimas[\"time\"].ge(p1_range.iloc[0,0])\n",
    "        condition2 = p1_range_localminimas[\"time\"].le(p1_range_localmaximas.iloc[Pay3_index,0])\n",
    "        condition = condition1 & condition2\n",
    "        \n",
    "        Pay2 = p1_range_localminimas[condition == True]['low'].values\n",
    "    \n",
    "        try:\n",
    "            #finding the index of the 1st local minima in the series \"p1_range_localminimas\" as P2\n",
    "            condition1 = p1_range_localminimas[\"time\"].ge(p1_range.iloc[0,0])\n",
    "            condition2 = p1_range_localminimas[\"time\"].le(p1_range_localmaximas.iloc[Pay3_index,0])\n",
    "            condition = condition1 & condition2\n",
    "        \n",
    "            #to find the y value of the 1st local maxima:\n",
    "            Pay2 = p1_range_localminimas[condition == True]['low'].values\n",
    "            if len(Pay2) == 0:\n",
    "                #proceed with the next pay3 index and rerun the while loop\n",
    "                Pay3_index_range = Pay3_index_range + 1\n",
    "                Pay3 = p1_range_localmaximas.iloc[Pay3_index_range:,2].max()\n",
    "                Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "                continue\n",
    "            else:\n",
    "                #if value exists, find the minimum\n",
    "                Pay2 = min(Pay2)\n",
    "                break\n",
    "        except IndexError as err1:\n",
    "            print(\"IndexError:\", err1)\n",
    "            break\n",
    "        except ValueError as ve:\n",
    "            print(\"ValueError:\", ve)\n",
    "            continue\n",
    "        except TypeError as te:\n",
    "            print(\"TypeError:\", te)\n",
    "            break\n",
    "    \n",
    "            \n",
    "    #Making a new dataframe of the higher highs and higher lows approaching P3 in chronological order\n",
    "    LL_LH = create_empty_time_price_df()\n",
    "    \n",
    "    #Grabbing the data attached to Pay*\n",
    "    mask = Last_110['high'] == Pay1\n",
    "    pa1 = Last_110[mask].drop(['open','low','close'], axis=1).drop_duplicates(subset=['high'], keep='last').rename(columns={\"high\":\"price\"})\n",
    "    LL_LH_df = pd.concat([LL_LH, pa1], ignore_index=True)\n",
    "    \n",
    "    Pa2 = p1_range_localminimas[p1_range_localminimas['low'] == Pay2].drop(['open','high','close'], axis=1)\n",
    "    Pa2 = Pa2.drop_duplicates(subset=['low'], keep='last')\n",
    "    Pa2 = Pa2.rename(columns={\"low\":\"price\"})\n",
    "    LL_LH_df = pd.concat([LL_LH_df, Pa2], ignore_index=True)\n",
    "    LL_LH_df = pd.concat([LL_LH_df, convert_maxima_to_LL_LH_df(Pay3, p1_range_localmaximas)], ignore_index=True)\n",
    "    \n",
    "    #Resetting the values to avoid issues\n",
    "    Pay2 = Pay1_index = Pay3_index = 0\n",
    "    \n",
    "    #Assigning new values to find new sets of Pa2, Pa3\n",
    "    Pay1 = Pay3\n",
    "    Pay1_index = compute_index_Pa_x(Pay1, p1_range_localmaximas)\n",
    "    \n",
    "    #Resetting the values to avoid issues\n",
    "    Pay3 = Pay3_index = 0\n",
    "    \n",
    "    #Finding the initial value of Pay3\n",
    "    try:\n",
    "        Pay3 = p1_range_localmaximas.iloc[Pay1_index+1:,2].max()\n",
    "        Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "    except IndexError as err1:\n",
    "        print('There is no next p3. Continue with the external P1-P2-P3...')\n",
    "        Pay3 = None\n",
    "    \n",
    "    if Pay3 != None:\n",
    "        #Finding the values of the lower lows and lower highs and appending it to the LL_HH_df\n",
    "        while True:\n",
    "            Pay3_index_range = 0\n",
    "            try:\n",
    "                # Check if the current Pay3_index is beyond the end of p1_range_localminimas\n",
    "                if Pay3_index > len(p1_range_localmaximas):\n",
    "                    print(f\"End of p1_range_localmaximas reached.{Pay3_index}\")\n",
    "                    break\n",
    "                    \n",
    "                #finding the index of the next local maxima\n",
    "                condition1 = p1_range_localminimas[\"time\"].ge(p1_range_localmaximas.iloc[Pay1_index,0])\n",
    "                condition2 = p1_range_localminimas[\"time\"].le(p1_range_localmaximas.iloc[Pay3_index,0])\n",
    "                condition = condition1 & condition2\n",
    "        \n",
    "                \n",
    "                #to find the y value of the next local minima:\n",
    "                Pay2 = p1_range_localminimas[condition == True]['low'].values\n",
    "                \n",
    "                #previous ll index\n",
    "                pLL_index = LL_LH_df[LL_LH_df['price'] == Pay1].index[0] - 1\n",
    "                pLLy = LL_LH_df.iloc[pLL_index,1]\n",
    "        \n",
    "                #if Pay2 isnt existing for the current Pay3\n",
    "                condition3 = len(Pay2) == 0\n",
    "                \n",
    "                #if the current Pay2 is more than the previous ll\n",
    "                try:\n",
    "                    condition4 = p1_range_localminimas[condition == True]['low'].values.min() > pLLy\n",
    "                except ValueError as err2:\n",
    "                    Pay3_index = Pay3_index+1\n",
    "                    Pay3 = p1_range_localmaximas.iloc[Pay3_index:,2].max()\n",
    "                    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "                    continue\n",
    "                    \n",
    "                if condition3 or condition4:\n",
    "                    #proceed with the next pay3 index and rerun the while loop\n",
    "                    Pay2 = 0\n",
    "                    Pay3_index_range = Pay3_index+1\n",
    "                    Pay3 = p1_range_localmaximas.iloc[Pay3_index_range:,2].max()\n",
    "                    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "                    continue\n",
    "                else:\n",
    "                    Pay2=Pay2.min()\n",
    "                    #Appending to the LL_LH_df \n",
    "                    condition5 = (p1_range_localminimas['low'] == Pay2) & condition\n",
    "                    LL_LH_df = pd.concat([LL_LH_df, convert_minima_to_LL_LH_df(Pay2, condition5, p1_range_localminimas)], ignore_index=True)\n",
    "                    LL_LH_df = pd.concat([LL_LH_df, convert_maxima_to_LL_LH_df(Pay3, p1_range_localmaximas)], ignore_index=True)\n",
    "                    \n",
    "                    #Assigning new values to find new sets of Pa2, Pa3\n",
    "                    Pay1 = Pay3\n",
    "                    Pay1_index = compute_index_Pa_x(Pay1, p1_range_localmaximas)\n",
    "                    \n",
    "                    #Finding the initial value of Pay3\n",
    "                    Pay3 = p1_range_localmaximas.iloc[Pay1_index+1:,2].max()\n",
    "                    Pay3_index = compute_index_Pa_x(Pay3, p1_range_localmaximas)\n",
    "                    continue\n",
    "            except IndexError as err1:\n",
    "                break\n",
    "            except TypeError as te:\n",
    "                break\n",
    "    \n",
    "        #Append Max_110 to the dataframe:\n",
    "        Min_110 = Min_110.drop(['open','high','close'], axis=1).rename(columns={\"low\":\"price\"})\n",
    "        LL_LH_df = pd.concat([LL_LH_df, Min_110], ignore_index=True)\n",
    "        \n",
    "        # Create a tuple combining the list of possible p1-p2-p3 (initial values)\n",
    "        p1_p2_p3i = create_tuples_p1_p3(LL_LH_df)\n",
    "        \n",
    "        # finding the right p1-p2-p3 in terms of ratios\n",
    "        p1_p2_p3_index = []\n",
    "        for i in p1_p2_p3i:\n",
    "            p3i=i[0]\n",
    "            p2i=i[1]\n",
    "            p1i=i[2]\n",
    "            p3y_p2y = LL_LH_df.iloc[p3i,1] - LL_LH_df.iloc[p2i,1]\n",
    "            p2y_p1y = LL_LH_df.iloc[p2i,1] - LL_LH_df.iloc[p1i,1]\n",
    "            p3x_p2x = LL_LH_df.iloc[p3i,0] - LL_LH_df.iloc[p2i,0]\n",
    "            p2x_p1x = LL_LH_df.iloc[p2i,0] - LL_LH_df.iloc[p1i,0]\n",
    "        \n",
    "            # conditions for finding the right p1-p2-p3\n",
    "            condition1 = 1.027 <= abs(p3y_p2y/p2y_p1y) <= 1.9286\n",
    "            try:\n",
    "                # condition2 = 0.333 <= abs(p3x_p2x/p2x_p1x) <= 5\n",
    "                condition2 = 0.1 <= abs(p3x_p2x/p2x_p1x) <= 5\n",
    "            except ZeroDivisionError as err1:\n",
    "                condition2 = False\n",
    "                \n",
    "            condition3 = p2x_p1x > pd.Timedelta(minutes=1)\n",
    "            condition4 = pd.Timedelta(minutes=2) <= p2x_p1x <= pd.Timedelta(minutes=24)\n",
    "            condition5 = pd.Timedelta(minutes=2) <= p3x_p2x <= pd.Timedelta(minutes=21)\n",
    "            condition = condition1 & condition2 & condition3 & condition4 & condition5\n",
    "            \n",
    "            if condition:\n",
    "                p1_p2_p3_index.append(i)\n",
    "    \n",
    "            p1, p2, p3 = create_empty_p1_and_p2_and_p3_df()\n",
    "        \n",
    "        if len(p1_p2_p3_index) == 0:\n",
    "            return p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3\n",
    "            \n",
    "        else:\n",
    "            for p3i, p2i, p1i in p1_p2_p3_index:\n",
    "                new_p3 = LL_LH_df.iloc[[p3i]]\n",
    "                new_p2 = LL_LH_df.iloc[[p2i]]\n",
    "                new_p1 = LL_LH_df.iloc[[p1i]]\n",
    "                p3 = pd.concat([p3,new_p3], ignore_index=True)\n",
    "                p2 = pd.concat([p2,new_p2], ignore_index=True)\n",
    "                p1 = pd.concat([p1,new_p1], ignore_index=True)\n",
    "                return  p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3\n",
    "        \n",
    "        if len(p1) != len(p2):\n",
    "            print(\"Index error! P1 and P2 doesn't match!\")\n",
    "            return p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3\n",
    "            \n",
    "    elif Pay3 == None:\n",
    "        p1, p2, p3 = create_empty_p1_and_p2_and_p3_df()\n",
    "        return p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44ccc27f-6d19-4fdd-b882-bd9dccba3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validate_and_sell(Last_110, sell_tp):\n",
    "#     TP1_price = None\n",
    "#     # OBTAINING THE EXTERNAL p1-p2-p3\n",
    "#     (\n",
    "#         p1_range_localminimas,\n",
    "#         p1_range_localmaximas,\n",
    "#         HH_HL_df,\n",
    "#         p1,\n",
    "#         p2,\n",
    "#         p3\n",
    "#     ) = obtain_p1_p2_p3(Last_110)\n",
    "    \n",
    "#     # FINDING THE VALUES OF THE OHLC DATAFRAME FROM THE EXTERNAL P2 AND P3 to HAVE THE INTERNAL P1-P2-P3\n",
    "#     if not len(p1) == 0 and not len(p2) == 0:\n",
    "#         p1_internal_range_start_time = p2[\"time\"].iloc[-1]\n",
    "#         p1_internal_range_end_time = p3[\"time\"].iloc[-1]\n",
    "        \n",
    "#         mask = (p1_internal_range_start_time <= Last_110[\"time\"]) & (Last_110[\"time\"] <= p1_internal_range_end_time)\n",
    "#         p1_internal_range = Last_110[mask]\n",
    "        \n",
    "#     try: \n",
    "#         (\n",
    "#             p1_range_localminimas_internal,\n",
    "#             p1_range_localmaximas_internal,\n",
    "#             HH_HL_df_internal, p1_internal,\n",
    "#             p2_internal,\n",
    "#             p3_internal\n",
    "#         ) = obtain_p1_p2_p3(p1_internal_range)\n",
    "#     except TypeError as TE:\n",
    "#         p1_internal, p2_internal, p3_internal = create_empty_p1_and_p2_and_p3_df()\n",
    "#         p1_range_localminimas_internal = p1_range_localmaximas_internal = create_empty_time_open_high_low_close_df()\n",
    "#         HH_HL_df_internal = create_empty_time_price_df()\n",
    "#     except UnboundLocalError as ULE:\n",
    "#         #if there is no p1-p2-p3 because of the time limits, it will return a ULE, therefore, find the p1-p2-p3 with another dataframe\n",
    "#         #tail 42 is just temporary, gather more data for this\n",
    "#         p1_internal_range = Last_110.tail(42)\n",
    "\n",
    "#         try:\n",
    "#             (\n",
    "#                 p1_range_localminimas_internal,\n",
    "#                 p1_range_localmaximas_internal,\n",
    "#                 HH_HL_df_internal, p1_internal,\n",
    "#                 p2_internal,\n",
    "#                 p3_internal\n",
    "#             ) = obtain_p1_p2_p3(p1_internal_range)\n",
    "#         except (TypeError, UnboundLocalError) as TE_ULE:\n",
    "#             p1_internal, p2_internal, p3_internal = create_empty_p1_and_p2_and_p3_df()\n",
    "#             p1_range_localminimas_internal = p1_range_localmaximas_internal = create_empty_time_open_high_low_close_df()\n",
    "#             HH_HL_df_internal = create_empty_time_price_df()\n",
    "        \n",
    "            \n",
    "    \n",
    "#     # APPEND THE VALUES OF THE INTERNAL P1, P2, P3 to the external one. \n",
    "#     p1 = pd.concat([p1,p1_internal], ignore_index=True)\n",
    "#     p2 = pd.concat([p2,p2_internal], ignore_index=True)\n",
    "#     p3 = pd.concat([p3,p3_internal], ignore_index=True)\n",
    "    \n",
    "#     #SETTING THE INITIAL VALUE OF SELL TO \"NONE\"\n",
    "#     Sell = None\n",
    "    \n",
    "#     if (len(p1) == 0 and len(p2) == 0) and (len(p1) != len(p2)):\n",
    "#         Sell = False\n",
    "#         SL_price = None\n",
    "#         OB_size = None\n",
    "#         Entry_price = None\n",
    "#         SL_size = None\n",
    "#         p2_bos = p4 = create_empty_time_price_df()\n",
    "#         return Sell, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "        \n",
    "    \n",
    "#     #FINDING P4 RANGE DATAFRAME\n",
    "#     p4_range_start_time = p3[\"time\"].iloc[-1]\n",
    "#     p4_range_end_time = Last_110[\"time\"].iloc[-1]\n",
    "#     mask = (p4_range_start_time <= Last_110[\"time\"]) & (Last_110[\"time\"] <= p4_range_end_time)\n",
    "#     p4_range = Last_110[mask]\n",
    "    \n",
    "#     #FIND THE INITIAL VALUE OF P4 ( MINIMUM LOW IN THE P4 RANGE)\n",
    "#     p4y = p4_range[\"low\"].min()\n",
    "#     mask = p4_range[\"low\"] == p4y\n",
    "#     p4 = p4_range[mask].drop(['open','high','close'], axis=1).rename(columns={\"low\":\"price\"}).iloc[[-1]]\n",
    "    \n",
    "#     # FINDING EVERY POSSIBLE P2 AFTER BOS (IF THERE IS A BOS)\n",
    "#     p4y = p4[\"price\"].iloc[0]\n",
    "#     p2_index = 0\n",
    "#     p2_bos = pd.DataFrame(columns=['time','price'])\n",
    "#     p2_bos = pd.DataFrame({'time': pd.Series(dtype='datetime64[ns]'), 'price': pd.Series(dtype='float')})\n",
    "    \n",
    "#     while p2_index < len(p2):\n",
    "#         if p2[\"price\"].iloc[p2_index] > p4y:\n",
    "#             #GRAB THE INDIVIDUAL P2 THAT CAUSED BOS\n",
    "#             p2_bos = pd.concat([p2_bos,p2.iloc[[p2_index]]], ignore_index=True)\n",
    "#             p2_index += 1\n",
    "#         else:\n",
    "#             p2_index += 1\n",
    "#             continue  \n",
    "            \n",
    "    \n",
    "#     # DECIDING WHETHER TO SELL OR NOT\n",
    "#     if len(p2_bos) == 0:\n",
    "#         Sell = False\n",
    "#         SL_price = None\n",
    "#         OB_size = None\n",
    "#         Entry_price = None\n",
    "#         SL_size = None\n",
    "#         Sell, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "#     else:\n",
    "#         SL_price = p3[\"price\"].iloc[0] + 0.00007\n",
    "#         OB_size = round(p3[\"price\"].iloc[0] - p2_bos[\"price\"].min(), 5)\n",
    "#         Entry_price = round(p2_bos[\"price\"].min() + 0.6*OB_size - 0.00007, 5)\n",
    "#         SL_size = round(SL_price - Entry_price, 5)\n",
    "#         TP1_price = round(Entry_price - (SL_size * 5), 5)\n",
    "#         TP_size = Entry_price - sell_tp\n",
    "#         RR = TP_size / SL_size\n",
    "\n",
    "#         if RR >= 5:\n",
    "#             Sell = True\n",
    "#             return Sell, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4\n",
    "#         else:\n",
    "#             Sell = False\n",
    "#             return Sell, SL_price, TP1_price, OB_size, Entry_price, SL_size, p1, p2, p2_bos, p3, p4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4e7b88-cec7-4070-9f4e-12bdbded0f65",
   "metadata": {},
   "source": [
    "### START TO DELETE CALLING OF THE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e14968a-c94f-468b-a69f-cce6bfaa08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_range_localminimas, p1_range_localmaximas, LL_LH_df, p1, p2, p3 = obtain_p1_p2_p3(Last_110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cbfcfae-52fe-4c39-874a-97af164df081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-14 15:05:00</td>\n",
       "      <td>161.591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    price\n",
       "0 2025-01-14 15:05:00  161.591"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9dc27654-f2c9-41df-9299-fdd83a7b2995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-14 15:27:00</td>\n",
       "      <td>161.793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    price\n",
       "0 2025-01-14 15:27:00  161.793"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "601d6495-98b7-4667-b84f-4131eeb54519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-14 15:33:00</td>\n",
       "      <td>161.566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time    price\n",
       "0 2025-01-14 15:33:00  161.566"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c24c9-912d-49d0-8d61-86db32f968c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37757a6b-9bda-43dd-9402-c6035a58c9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d92f88ea-3738-44ff-aefc-c5bfe5d09521",
   "metadata": {},
   "source": [
    " ### END TO DELETE CALLING OF THE FUNCTIONS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
